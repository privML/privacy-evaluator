{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-10T13:59:47.272452Z",
     "iopub.status.busy": "2021-06-10T13:59:47.271855Z",
     "iopub.status.idle": "2021-06-10T13:59:57.239566Z",
     "shell.execute_reply": "2021-06-10T13:59:57.238711Z",
     "shell.execute_reply.started": "2021-06-10T13:59:47.272362Z"
    }
   },
   "source": [
    "# Membership Inference Attack Analysis Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/privML/privacy-evaluator/blob/team1sprint4/notebooks/membership_inference_attack_analysis.ipynb\"><img src=\"https://raw.githubusercontent.com/privML/privacy-evaluator/team1sprint4/notebooks/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/privML/privacy-evaluator/blob/team1sprint4/notebooks/membership_inference_attack_analysis.ipynb\"><img src=\"https://raw.githubusercontent.com/privML/privacy-evaluator/team1sprint4/notebooks/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In this notebook, we want to show you how to use the `privacy-evaluator` tool to perform a Membership Inference Attack Analysis on either a PyTorch or Tensorflow model. As an example we will conduct the Membership Inference Black Box Rule-Based Attack and apply an in-depth analysis on this method. To get a more general introduction into the  Membership Inference Attacks, please see [membership_inference_attack.ipynb](https://github.com/privML/privacy-evaluator/blob/team1sprint4/notebooks/membership_inference_attack.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, you should set the notebook's runtime to use a GPU (e.g. if Colab is used go to ***Runtime > Change runtime type > Hardware accelerator***). Now we can install the `privacy-evaluator` package and import all needed modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-10T13:59:57.241810Z",
     "iopub.status.busy": "2021-06-10T13:59:57.241534Z",
     "iopub.status.idle": "2021-06-10T14:00:24.667032Z",
     "shell.execute_reply": "2021-06-10T14:00:24.666076Z",
     "shell.execute_reply.started": "2021-06-10T13:59:57.241784Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip3 install git+https://github.com/privML/privacy-evaluator@team1sprint4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-10T14:00:24.671136Z",
     "iopub.status.busy": "2021-06-10T14:00:24.670845Z",
     "iopub.status.idle": "2021-06-10T14:00:33.730859Z",
     "shell.execute_reply": "2021-06-10T14:00:33.729906Z",
     "shell.execute_reply.started": "2021-06-10T14:00:24.671108Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import privacy_evaluator.models.torch.dcti.dcti as torch_dcti\n",
    "import privacy_evaluator.models.tf.dcti.dcti as tf_dcti \n",
    "\n",
    "from privacy_evaluator.datasets.tf.cifar10 import TFCIFAR10\n",
    "from privacy_evaluator.datasets.torch.cifar10 import TorchCIFAR10\n",
    "\n",
    "from privacy_evaluator.classifiers.classifier import Classifier\n",
    "\n",
    "from privacy_evaluator.attacks.membership_inference import MembershipInferenceAttackAnalysis\n",
    "from privacy_evaluator.attacks.membership_inference import MembershipInferenceBlackBoxRuleBasedAttack\n",
    "\n",
    "from privacy_evaluator.attacks.membership_inference.data_structures.attack_input_data import AttackInputData\n",
    "from privacy_evaluator.attacks.membership_inference.data_structures.slicing import Slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conduct Membership Inference Attack Analysis\n",
    "\n",
    "Now we can start with conducting the Membership Inference Attacks Analysis. Therefore, we prepared two similar paths: one for the PyTorch model and one for the TensorFlow model. For both paths, we use simple neural networks trained on the CIFAR-10 dataset and implement a Lightweight Deep Convolutional Neural Network architecture (for more details, please read the following paper: https://www.scitepress.org/Papers/2018/67520/67520.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch\n",
    "\n",
    "We start the analysis with the PyTorch model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load CIFAR10 Dataset\n",
    "\n",
    "Before we can start to conduct the membership inference attack analysis, we need to load the dataset. The CIFAR10 dataset needs to be preprocessed in a specific manner to work for the PyTorch model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR10 dataset as numpy array\n",
    "x_train, y_train, x_test, y_test = TorchCIFAR10.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare target model\n",
    "\n",
    "Now, we need to initialize our pre-trained Lightweight Deep Convolutional Neural Network (short DCTI) as a generic `Classifier`. Therefore we need to specify the loss function used to train the model (in our case the `torch.nn.CrossEntropyLoss`), the number of classes and the input shape of our CIFAR-10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-10T14:00:33.732866Z",
     "iopub.status.busy": "2021-06-10T14:00:33.732493Z",
     "iopub.status.idle": "2021-06-10T14:01:58.589093Z",
     "shell.execute_reply": "2021-06-10T14:01:58.588276Z",
     "shell.execute_reply.started": "2021-06-10T14:00:33.732828Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initalize PyTorch model as a Classifier\n",
    "target_model = Classifier(\n",
    "    torch_dcti.load_dcti(), # PyTorch DCTI \n",
    "    loss=torch.nn.CrossEntropyLoss(reduction=\"none\"), # Loss function of the PyTorch model\n",
    "    nb_classes=TorchCIFAR10.N_CLASSES, # Number of classes of the CIFAR10 dataset\n",
    "    input_shape=TorchCIFAR10.INPUT_SHAPE # Input shape of the CIFAR10 dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-10T14:01:58.591577Z",
     "iopub.status.busy": "2021-06-10T14:01:58.591298Z",
     "iopub.status.idle": "2021-06-10T14:01:58.596559Z",
     "shell.execute_reply": "2021-06-10T14:01:58.595766Z",
     "shell.execute_reply.started": "2021-06-10T14:01:58.591549Z"
    }
   },
   "source": [
    "#### Perpare attack analysis\n",
    "\n",
    "Next, we prepare our attack analysis. To initialize our attack analysis we define the Membership Inference Attack method we want to perform (in this case we use the `MembershipInferenceBlackBoxRuleBasedAttack`) and the Attack Input Data. The Attack Input Data consists of two different sets. The first contains the data (`x_train`) and its corresponding labels (`y_train`) which were used to train the target model. The second contains the data (`x_test`) and its corresponding labels (`y_test`) which were not part of the training process of the target model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = MembershipInferenceAttackAnalysis(\n",
    "    MembershipInferenceBlackBoxRuleBasedAttack, \n",
    "    AttackInputData(\n",
    "        x_train[:100], \n",
    "        y_train[:100], \n",
    "        x_test[:100], \n",
    "        y_test[:100]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the slicing\n",
    "\n",
    "Now we can define the slicing for our analysis. The slicing defines how the data will be sliced. Each slice will then be analysed separately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slicing = Slicing(\n",
    "    entire_dataset=True, \n",
    "    by_class=True, \n",
    "    by_classification_correctness=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform Membership Inference Attack Analysis\n",
    "\n",
    "Finally, we can perform our Membership Inference Attack Analysis. Therefore, we input the target model, the data that should be analysed, the membership labels (i.e. the labels which correctly describe if a data point is a member of the training dataset or not) and the splicing specification into the `analyse()` method. As a result, we get for each slice the indices of the corresponding data points, a human-readable description of the slice and the advantage score of the Membership Inference Attack (for more details about the advantage score, please read the following paper: https://arxiv.org/abs/1709.01604)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-10T14:01:58.598362Z",
     "iopub.status.busy": "2021-06-10T14:01:58.597994Z",
     "iopub.status.idle": "2021-06-10T14:02:27.468972Z",
     "shell.execute_reply": "2021-06-10T14:02:27.468098Z",
     "shell.execute_reply.started": "2021-06-10T14:01:58.598322Z"
    }
   },
   "outputs": [],
   "source": [
    "result = analysis.analyse(\n",
    "    target_model, \n",
    "    np.concatenate((x_train[:100], x_test[:100])), \n",
    "    np.concatenate((y_train[:100], y_test[:100])), \n",
    "    np.concatenate((np.ones(len(x_train[:100])), np.zeros(len(x_test[:100])))), \n",
    "    slicing\n",
    ")\n",
    "\n",
    "print(\"\\n\".join((str(r) for r in result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow\n",
    "\n",
    "Now we do the same with the TensorFlow model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load CIFAR10 Dataset\n",
    "\n",
    "Again, before we can start to conduct the membership inference attack analysis, we need to load the dataset. The CIFAR10 dataset needs to be preprocessed in a specific manner to work for the TensorFlow model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR10 dataset as numpy array\n",
    "x_train, y_train, x_test, y_test = TFCIFAR10.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare target model\n",
    "\n",
    "Now, we need to initialize our pre-trained Lightweight Deep Convolutional Neural Network (short DCTI) as a generic `Classifier`. Therefore we need to specify the loss function used to train the model (in our case the `tf.keras.losses.CategoricalCrossentropy`), the number of classes and the input shape of our CIFAR-10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initalize TensorFlow target model\n",
    "target_model = Classifier(\n",
    "    tf_dcti.load_dcti(), # TensorFlow DCTI\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(), # Loss function of the TensorFlow target model\n",
    "    nb_classes=TFCIFAR10.N_CLASSES, # Number of classes of the CIFAR10 dataset\n",
    "    input_shape=TFCIFAR10.INPUT_SHAPE # Input shape of the CIFAR10 dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perpare attack analysis\n",
    "\n",
    "Next, we prepare our attack analysis. To initialize our attack analysis we define the Membership Inference Attack method we want to perform (in this case we use the `MembershipInferenceBlackBoxRuleBasedAttack`) and the Attack Input Data. The Attack Input Data consists of two different sets. The first contains the data (`x_train`) and its corresponding labels (`y_train`) which were used to train the target model. The second contains the data (`x_test`) and its corresponding labels (`y_test`) which were not part of the training process of the target model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_analysis = MembershipInferenceAttackAnalysis(\n",
    "    MembershipInferenceBlackBoxRuleBasedAttack, \n",
    "    AttackInputData(\n",
    "        x_train[:100], \n",
    "        y_train[:100], \n",
    "        x_test[:100], \n",
    "        y_test[:100]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the slicing\n",
    "\n",
    "Now we can define the slicing for our analysis. The slicing defines how the data will be sliced. Each slice will then be analysed separately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slicing = Slicing(\n",
    "    entire_dataset=True, \n",
    "    by_class=True, \n",
    "    by_classification_correctness=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform Membership Inference Attack Analysis\n",
    "\n",
    "Finally, we can perform our Membership Inference Attack Analysis. Therefore, we input the target model, the data that should be analysed, the membership labels (i.e. the labels which correctly describe if a data point is a member of the training dataset or not) and the splicing specification into the `analyse()` method. As a result, we get for each slice the indices of the corresponding data points, a human-readable description of the slice and the advantage score of the Membership Inference Attack (for more details about the advantage score, please read the following paper: https://arxiv.org/abs/1709.01604)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = attack_analysis.analyse(\n",
    "    target_model, \n",
    "    np.concatenate((x_train[:100], x_test[:100])), \n",
    "    np.concatenate((y_train[:100], y_test[:100])), \n",
    "    np.concatenate((np.ones(len(x_train[:100])), np.zeros(len(x_test[:100])))), \n",
    "    slicing\n",
    ")\n",
    "\n",
    "print(\"\\n\".join((str(r) for r in result)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
