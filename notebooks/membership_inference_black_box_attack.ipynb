{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "privacy-evaluator-venv",
      "language": "python",
      "name": "privacy-evaluator-venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "membership_inference_black_box_attack.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rf_QO8flWx6_"
      },
      "source": [
        "# Membership Inference Black Box Attack Examples"
      ],
      "id": "Rf_QO8flWx6_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKAYn2M4Wx7F"
      },
      "source": [
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/privML/privacy-evaluator/blob/main/notebooks/membership_inference_black_box_attack.ipynb\"><img src=\"https://raw.githubusercontent.com/privML/privacy-evaluator/team1sprint4/notebooks/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/privML/privacy-evaluator/blob/main/notebooks/membership_inference_black_box_attack.ipynb\"><img src=\"https://raw.githubusercontent.com/privML/privacy-evaluator/main/notebooks/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>\n",
        "\n",
        "\n"
      ],
      "id": "WKAYn2M4Wx7F"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ia0VmlzeWx7H"
      },
      "source": [
        "## Overview\n",
        "\n",
        "In this notebook, we want to show you how to use the `privacy-evaluator` tool to perform the Membership Inference Attacks Black Box Attack on both, a provided PyTorch and a provided Tensorflow model."
      ],
      "id": "Ia0VmlzeWx7H"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DH6rB9KSWx7J"
      },
      "source": [
        "## Setup\n",
        "\n",
        "First, you should set the notebook's runtime to use a GPU (e.g. if Colab is used go to ***Runtime > Change runtime type > Hardware accelerator***). Now we can install the `privacy-evaluator` package and import all needed modules."
      ],
      "id": "DH6rB9KSWx7J"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNU7L3GCWx7M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94bf7d98-1d11-4009-c18a-0d7664516f53"
      },
      "source": [
        "!pip3 install git+https://github.com/privML/privacy-evaluator@team1sprint4"
      ],
      "id": "lNU7L3GCWx7M",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/privML/privacy-evaluator@team1sprint4\n",
            "  Cloning https://github.com/privML/privacy-evaluator (to revision team1sprint4) to /tmp/pip-req-build-fn0otpvs\n",
            "  Running command git clone -q https://github.com/privML/privacy-evaluator /tmp/pip-req-build-fn0otpvs\n",
            "  Running command git checkout -b team1sprint4 --track origin/team1sprint4\n",
            "  Switched to a new branch 'team1sprint4'\n",
            "  Branch 'team1sprint4' set up to track remote branch 'team1sprint4' from 'origin'.\n",
            "Requirement already satisfied (use --upgrade to upgrade): privacy-evaluator==0.1 from git+https://github.com/privML/privacy-evaluator@team1sprint4 in /usr/local/lib/python3.7/dist-packages\n",
            "Requirement already satisfied: adversarial-robustness-toolbox[pytorch,tensorflow]==1.6.2 in /usr/local/lib/python3.7/dist-packages (from privacy-evaluator==0.1) (1.6.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from privacy-evaluator==0.1) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from privacy-evaluator==0.1) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from privacy-evaluator==0.1) (1.1.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from privacy-evaluator==0.1) (1.9.0+cu102)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from privacy-evaluator==0.1) (2.5.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from privacy-evaluator==0.1) (0.10.0+cu102)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox[pytorch,tensorflow]==1.6.2->privacy-evaluator==0.1) (4.41.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox[pytorch,tensorflow]==1.6.2->privacy-evaluator==0.1) (57.0.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox[pytorch,tensorflow]==1.6.2->privacy-evaluator==0.1) (1.4.1)\n",
            "Requirement already satisfied: numba~=0.53.1 in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox[pytorch,tensorflow]==1.6.2->privacy-evaluator==0.1) (0.53.1)\n",
            "Requirement already satisfied: scikit-learn<0.24.3,>=0.22.2 in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox[pytorch,tensorflow]==1.6.2->privacy-evaluator==0.1) (0.22.2.post1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox[pytorch,tensorflow]==1.6.2->privacy-evaluator==0.1) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-addons; extra == \"tensorflow\" in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox[pytorch,tensorflow]==1.6.2->privacy-evaluator==0.1) (0.13.0)\n",
            "Requirement already satisfied: h5py; extra == \"tensorflow\" in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox[pytorch,tensorflow]==1.6.2->privacy-evaluator==0.1) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->privacy-evaluator==0.1) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->privacy-evaluator==0.1) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->privacy-evaluator==0.1) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->privacy-evaluator==0.1) (0.10.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->privacy-evaluator==0.1) (2018.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->privacy-evaluator==0.1) (3.7.4.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->privacy-evaluator==0.1) (2.5.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->privacy-evaluator==0.1) (0.2.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow->privacy-evaluator==0.1) (0.12.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->privacy-evaluator==0.1) (3.12.4)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow->privacy-evaluator==0.1) (2.5.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->privacy-evaluator==0.1) (1.12.1)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->privacy-evaluator==0.1) (1.1.2)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->privacy-evaluator==0.1) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->privacy-evaluator==0.1) (3.3.0)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow->privacy-evaluator==0.1) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow->privacy-evaluator==0.1) (0.36.2)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->privacy-evaluator==0.1) (1.34.1)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->privacy-evaluator==0.1) (0.4.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->privacy-evaluator==0.1) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->privacy-evaluator==0.1) (1.12)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->privacy-evaluator==0.1) (7.1.2)\n",
            "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in /usr/local/lib/python3.7/dist-packages (from numba~=0.53.1->adversarial-robustness-toolbox[pytorch,tensorflow]==1.6.2->privacy-evaluator==0.1) (0.36.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.24.3,>=0.22.2->adversarial-robustness-toolbox[pytorch,tensorflow]==1.6.2->privacy-evaluator==0.1) (1.0.1)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons; extra == \"tensorflow\"->adversarial-robustness-toolbox[pytorch,tensorflow]==1.6.2->privacy-evaluator==0.1) (2.7.1)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py; extra == \"tensorflow\"->adversarial-robustness-toolbox[pytorch,tensorflow]==1.6.2->privacy-evaluator==0.1) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->privacy-evaluator==0.1) (1.8.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->privacy-evaluator==0.1) (0.4.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->privacy-evaluator==0.1) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->privacy-evaluator==0.1) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->privacy-evaluator==0.1) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->privacy-evaluator==0.1) (1.31.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->privacy-evaluator==0.1) (3.3.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow->privacy-evaluator==0.1) (1.3.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow->privacy-evaluator==0.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow->privacy-evaluator==0.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow->privacy-evaluator==0.1) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow->privacy-evaluator==0.1) (2.10)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->privacy-evaluator==0.1) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->privacy-evaluator==0.1) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->privacy-evaluator==0.1) (0.2.8)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow->privacy-evaluator==0.1) (4.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow->privacy-evaluator==0.1) (3.1.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->privacy-evaluator==0.1) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.5->tensorflow->privacy-evaluator==0.1) (3.4.1)\n",
            "Building wheels for collected packages: privacy-evaluator\n",
            "  Building wheel for privacy-evaluator (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for privacy-evaluator: filename=privacy_evaluator-0.1-cp37-none-any.whl size=112447660 sha256=25b02e88d677acb2ab292a86f2e31b7432e95f19832167a04d2f82c39a342ad2\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-vwrsvw9w/wheels/69/13/a0/092a33dd139764bcce399f23cf92c195049da93631adb751c7\n",
            "Successfully built privacy-evaluator\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9d7ab468"
      },
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow.python.ops.numpy_ops.np_config as np_config\n",
        "np_config.enable_numpy_behavior()\n",
        "\n",
        "import privacy_evaluator.models.torch.dcti.dcti as torch_dcti\n",
        "import privacy_evaluator.models.tf.dcti.dcti as tf_dcti \n",
        "\n",
        "from privacy_evaluator.datasets.tf.cifar10 import TFCIFAR10\n",
        "from privacy_evaluator.datasets.torch.cifar10 import TorchCIFAR10\n",
        "\n",
        "from privacy_evaluator.classifiers.classifier import Classifier\n",
        "\n",
        "from privacy_evaluator.attacks.membership_inference.black_box import MembershipInferenceBlackBoxAttack\n",
        "from privacy_evaluator.attacks.membership_inference import MembershipInferenceAttackAnalysis\n",
        "\n",
        "from privacy_evaluator.metrics.privacy_risk_score import * \n",
        "from privacy_evaluator.output.user_output_privacy_score import UserOutputPrivacyScore\n",
        "\n",
        "from privacy_evaluator.attacks.membership_inference import MembershipInferenceAttackAnalysis\n",
        "\n",
        "from privacy_evaluator.attacks.membership_inference.data_structures.attack_input_data import AttackInputData\n",
        "from privacy_evaluator.attacks.membership_inference.data_structures.slicing import Slicing"
      ],
      "id": "9d7ab468",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUH4YQ4tWx7Q"
      },
      "source": [
        "## Conduct Membership Inference Black Box Attacks\n",
        "\n",
        "Now we can start with conducting the Membership Inference Black Box Attacks. Therefore, we prepared two instances of the attack: one attacking a PyTorch model and attacking a TensorFlow model. For both attacks, we implemented a simple neural network trained on the CIFAR-10 dataset. For details about the provided network have a look at the following paper: https://www.scitepress.org/Papers/2018/67520/67520.pdf)."
      ],
      "id": "mUH4YQ4tWx7Q"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2da0876"
      },
      "source": [
        "### PyTorch\n",
        "\n",
        "We start the evaluation of the PyTorch version of the model."
      ],
      "id": "b2da0876"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aQIN6UMWx7W"
      },
      "source": [
        "#### Prepare target model\n",
        "\n",
        "Now, we need to initialize our pre-trained Lightweight Deep Convolutional Neural Network (short DCTI) as a generic `Classifier`. Therefore we need to specify the loss function used to train the model (in our case the `torch.nn.CrossEntropyLoss`), the number of classes and the input shape of our CIFAR-10 dataset."
      ],
      "id": "7aQIN6UMWx7W"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fz4UuSxMWx7Y"
      },
      "source": [
        "# Initalize PyTorch model as a Classifier\n",
        "target_model = Classifier(\n",
        "    torch_dcti.load_dcti(), # PyTorch DCTI \n",
        "    loss=torch.nn.CrossEntropyLoss(reduction=\"none\"), # Loss function of the PyTorch model\n",
        "    nb_classes=TorchCIFAR10.N_CLASSES, # Number of classes of the CIFAR10 dataset\n",
        "    input_shape=TorchCIFAR10.INPUT_SHAPE # Input shape of the CIFAR10 dataset\n",
        ")"
      ],
      "id": "fz4UuSxMWx7Y",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sv_fGg8jWx7S"
      },
      "source": [
        "#### Load CIFAR10 Dataset\n",
        "\n",
        "Before we can start to conduct the membership inference attacks, we need to load the dataset. The CIFAR10 dataset needs to be preprocessed in a specific manner to work for the PyTorch model."
      ],
      "id": "sv_fGg8jWx7S"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcae11d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e9990f7-4fc7-4d55-9535-b5f6f170ced2"
      },
      "source": [
        "# Load CIFAR10 dataset as numpy array\n",
        "x_train, y_train, x_test, y_test = TorchCIFAR10.numpy()"
      ],
      "id": "dcae11d8",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7761c0c"
      },
      "source": [
        "#### Perform Membership Inference Black Box Attack\n",
        "\n",
        "We want to attack our target model with the Membership Inference  Black Box Attack. Thus, we initialize the attack with the target model and a dataset used to fit the attack model. The dataset consists of two different sets. The first contains the data (`x_train`) and its corresponding labels (`y_train`) which were used to train the target model. The second contains the data (`x_test`) and its corresponding labels (`y_test`) which were not part of the training process of the target model. After the initialization, we first need to fit the attack model before we can attack the target model. To attack certain data points, we simply input them into the `attack()` method. The result of the attack is an array holding the inferred membership status, 1 indicates a member and 0 indicates non-member."
      ],
      "id": "c7761c0c"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cd9e4799",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22a5cde1-d7c0-48bc-dd3a-8732cb881e72"
      },
      "source": [
        "attack = MembershipInferenceBlackBoxAttack(\n",
        "    target_model, \n",
        "    x_train[:100], \n",
        "    y_train[:100], \n",
        "    x_test[:100], \n",
        "    y_test[:100]\n",
        ")\n",
        "\n",
        "attack.fit()\n",
        "attack.attack(x_train[:100], y_train[:100])"
      ],
      "id": "cd9e4799",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "       0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n",
              "       0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
              "       1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5770d67d"
      },
      "source": [
        "#### Get machine-readable attack statistics\n",
        "\n",
        "Besides the inferred membership status, we can create more general statistics. To do so, we generate an attack output by providing again the data points which should be attacked and the correct inferred membership labels (in this case all attacked data points are part of the training dataset and thus for all of them a membership should be predicted by the attack model). As result, we get the accuracy, the train-to-test accuracy gap and the train-to-test ratio for the target model and the accuracy for the attack model."
      ],
      "id": "5770d67d"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eaa9ed6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "ac69fa2a-3c0c-46db-b9e7-d2ac084f682b"
      },
      "source": [
        "output = attack.attack_output(\n",
        "    x_train[:100], \n",
        "    y_train[:100], \n",
        "    np.ones((100,))\n",
        ")\n",
        "\n",
        "output.to_json()"
      ],
      "id": "8eaa9ed6",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'{\"target_model_train_accuracy\": 0.96, \"target_model_test_accuracy\": 0.87, \"target_model_train_to_test_accuracy_gap\": 0.08999999999999997, \"target_model_train_to_test_accuracy_ratio\": 1.103448275862069, \"attack_model_accuracy\": 0.74}'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRPu6e955n_B"
      },
      "source": [
        "#### Explanation of the outcome:\n",
        "\n",
        "Attack Model Accuracy:\n",
        "The attack model accuracy specifies how well the membership attack model performs in predicting if a given data point was used for training the target model. Since we have a two-class classification problem that the attack model solves (member or non-member), the lowest possible accuracy is 50% (random guessing for each sample). The best accuracy is at 100% if the model predicts every data point is sees right as member or non-member.\n",
        "\n",
        "Train-Test-Gap (difference):\n",
        "If your model has a train-test-gap larger than 5%, this could be a sign that your model overfits. Overfitting can be beneficial for successful membership inference attacks [1]. Therefore, you might want to reduce it by introducing regularization methods in your training, or using specific privacy methods [2,3], such as Differential Privacy [4].\n",
        "\n",
        "(For References, please see last box)"
      ],
      "id": "dRPu6e955n_B"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpycszf2JBfw"
      },
      "source": [
        "#### Perpare attack analysis\n",
        "\n",
        "Next, we prepare our attack analysis. To initialize our attack analysis we define the Membership Inference Attack method we want to perform (in this case we use the `MembershipInferenceBlackBoxAttack`) and the Attack Input Data. The Attack Input Data consists of two different sets. The first contains the data (`x_train`) and its corresponding labels (`y_train`) which were used to train the target model. The second contains the data (`x_test`) and its corresponding labels (`y_test`) which were not part of the training process of the target model."
      ],
      "id": "fpycszf2JBfw"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7CAm0_aJD05"
      },
      "source": [
        "attack_analysis = MembershipInferenceAttackAnalysis(\n",
        "    MembershipInferenceBlackBoxAttack, \n",
        "    AttackInputData(\n",
        "        x_train[:100], \n",
        "        y_train[:100], \n",
        "        x_test[:100], \n",
        "        y_test[:100]\n",
        "    )\n",
        ")"
      ],
      "id": "h7CAm0_aJD05",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H52Z0hJyJHj6"
      },
      "source": [
        "#### Define the slicing\n",
        "\n",
        "Now we can define the slicing for our analysis. The slicing defines how the data will be sliced. Each slice will then be analysed separately. "
      ],
      "id": "H52Z0hJyJHj6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gk9F4EiCJJGq"
      },
      "source": [
        "slicing = Slicing(\n",
        "    entire_dataset=True, \n",
        "    by_class=True, \n",
        "    by_classification_correctness=True\n",
        ")"
      ],
      "id": "Gk9F4EiCJJGq",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUEf6yXOJLUm"
      },
      "source": [
        "#### Perform Membership Inference Attack Analysis\n",
        "\n",
        "Finally, we can perform our Membership Inference Attack Analysis. Therefore, we input the target model, the data that should be analysed, the membership labels (i.e. the labels which correctly describe if a data point is a member of the training dataset or not) and the splicing specification into the `analyse()` method. As a result, we get for each slice the indices of the corresponding data points, a human-readable description of the slice and the advantage score of the Membership Inference Attack (for more details about the advantage score, please read the following paper: https://arxiv.org/abs/1709.01604)."
      ],
      "id": "yUEf6yXOJLUm"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUTnIKUEJM8R",
        "outputId": "967b0d01-c6df-41ac-c688-fb39d0b421fc"
      },
      "source": [
        "result = attack_analysis.analyse(\n",
        "    target_model, \n",
        "    np.concatenate((x_train[:100], x_test[:100])), \n",
        "    np.concatenate((y_train[:100], y_test[:100])), \n",
        "    np.concatenate((np.ones(len(x_train[:100])), np.zeros(len(x_test[:100])))), \n",
        "    slicing\n",
        ")\n",
        "\n",
        "print(\"\\n\".join((str(r) for r in result)))"
      ],
      "id": "AUTnIKUEJM8R",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MembershipInferenceAttackAnalysisSliceResult(\n",
            "  Slice(\n",
            "    indices: [  0   1 ... 198 199]\n",
            "    desc: Entire dataset\n",
            "  )\n",
            "  advantage: 0.0700\n",
            ")\n",
            "MembershipInferenceAttackAnalysisSliceResult(\n",
            "  Slice(\n",
            "    indices: [  0   1 ... 198 199]\n",
            "    desc: Correctly classified\n",
            "  )\n",
            "  advantage: 0.0948\n",
            ")\n",
            "MembershipInferenceAttackAnalysisSliceResult(\n",
            "  Slice(\n",
            "    indices: [ 21  39 ... 186 187]\n",
            "    desc: Incorrectly classified\n",
            "  )\n",
            "  advantage: 0.1923\n",
            ")\n",
            "MembershipInferenceAttackAnalysisSliceResult(\n",
            "  Slice(\n",
            "    indices: [ 29  30 ... 197 198]\n",
            "    desc: Class=0\n",
            "  )\n",
            "  advantage: 0.0000\n",
            ")\n",
            "MembershipInferenceAttackAnalysisSliceResult(\n",
            "  Slice(\n",
            "    indices: [  4   5 ... 181 182]\n",
            "    desc: Class=1\n",
            "  )\n",
            "  advantage: 0.0000\n",
            ")\n",
            "MembershipInferenceAttackAnalysisSliceResult(\n",
            "  Slice(\n",
            "    indices: [  6  13 ... 184 186]\n",
            "    desc: Class=2\n",
            "  )\n",
            "  advantage: 0.1250\n",
            ")\n",
            "MembershipInferenceAttackAnalysisSliceResult(\n",
            "  Slice(\n",
            "    indices: [  9  17 ... 178 191]\n",
            "    desc: Class=3\n",
            "  )\n",
            "  advantage: 0.2462\n",
            ")\n",
            "MembershipInferenceAttackAnalysisSliceResult(\n",
            "  Slice(\n",
            "    indices: [  3  10 ... 158 194]\n",
            "    desc: Class=4\n",
            "  )\n",
            "  advantage: 0.0909\n",
            ")\n",
            "MembershipInferenceAttackAnalysisSliceResult(\n",
            "  Slice(\n",
            "    indices: [ 27  40 ... 142 185]\n",
            "    desc: Class=5\n",
            "  )\n",
            "  advantage: 0.1250\n",
            ")\n",
            "MembershipInferenceAttackAnalysisSliceResult(\n",
            "  Slice(\n",
            "    indices: [  0  19 ... 195 196]\n",
            "    desc: Class=6\n",
            "  )\n",
            "  advantage: 0.0000\n",
            ")\n",
            "MembershipInferenceAttackAnalysisSliceResult(\n",
            "  Slice(\n",
            "    indices: [  7  11 ... 187 199]\n",
            "    desc: Class=7\n",
            "  )\n",
            "  advantage: 0.0909\n",
            ")\n",
            "MembershipInferenceAttackAnalysisSliceResult(\n",
            "  Slice(\n",
            "    indices: [  8  62 ... 188 192]\n",
            "    desc: Class=8\n",
            "  )\n",
            "  advantage: 0.0000\n",
            ")\n",
            "MembershipInferenceAttackAnalysisSliceResult(\n",
            "  Slice(\n",
            "    indices: [  1   2 ... 176 189]\n",
            "    desc: Class=9\n",
            "  )\n",
            "  advantage: 0.0000\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5yIBZEGJQxi"
      },
      "source": [
        "#### Explanation of the outcome:\n",
        "##### Attacker Advantage:\n",
        "The attacker advantageis a score that relies on comparing the model output on member and non-member data points. The model outputs are probability values over all classes, and they are often different on member and non-member data points. Usually, the model is more confident on member data points, because it has seen them during training. When trying to find a threshold value to tell apart member and non-member samples by their different model outputs, the attacker has interest in finding the best ratio between false positives “fpr” (non-members that are classified as members) and true positives “tpr” (members that are correctly identifies as members). \n",
        "\n",
        "This best ratio is calculated as the max(tpr-fpr) over all threshold values and represents the attacker advantage. \n",
        "\n",
        "##### Slicing: Incorrectly classified:\n",
        "It is normal that the attacker is more successful to deduce membership on incorrectly classified samples than on correctly classified ones. This results from the fact, that model predictions are often better on training than on test data points, whereby your attack model might learn to predict incorrectly classified samples as non-members. If your model overfits the training data, this assumption might hold true often enough to make the attack seem more successful on this slice. If you wish to reduce that, pay attention to reducing your model’s overfitting.\n",
        "\n",
        "##### Slicing: Specific classes more vulnerable: \n",
        "It seems that the membership inference attack is more successful on your class X than on the other classes. Research has shown that the class distribution (and also the distribution of data points within one class) are factors that influence the vulnerability of a class for membership inference attacks [5].\n",
        "\n",
        "Also, small classes (belonging to minority groups) can be more prone to membership inference attacks [6]. One reason for this could be, that there is less data for that class, and therefore, the model overfits within this class. It might make sense to look into the vulnerable classes of your model again, and maybe add more data to them, use private synthetic data, or introduce privacy methods like Differential Privacy [6]. Attention, the use of Differential Privacy could have a negative influence on the performance of your model for the minority classes.\n",
        "\n",
        "\n",
        "(For References, please see last box)"
      ],
      "id": "K5yIBZEGJQxi"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvL2cVGTJSuO"
      },
      "source": [
        "#### Compute privacy risk score\n",
        "\n",
        "As a next step, we want to compute the privacy risk scores. To do so, we input the target model and the data points which should be evaluated to the respective function. The given data points are separated into a train and tests set. The train set contains of the data (`x_train`) and its corresponding labels (`y_train`) which were used to train the target model. The test set contains the data (`x_test`) and its corresponding labels (`y_test`) which were not part of the training process of the target model. As a result, we get privacy risk scores for each data point, separated into train and test scores. The resulting values indicate the probability of a data point being a member or not."
      ],
      "id": "QvL2cVGTJSuO"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwt-wkV_JXm3"
      },
      "source": [
        "# Compute membership privacy risk score for the PyTorch model\n",
        "(\n",
        "    train_privacy_risk_score, \n",
        "    test_privacy_risk_score\n",
        ") = compute_privacy_risk_score(\n",
        "    target_model, \n",
        "    x_train[:100], \n",
        "    y_train[:100], \n",
        "    x_test[:100], \n",
        "    y_test[:100]\n",
        ")"
      ],
      "id": "bwt-wkV_JXm3",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDl3RrF8JZLk"
      },
      "source": [
        "#### Get human-readable privacy risk score statistics\n",
        "\n",
        "Besides the privacy risk scores, we can create more human-readable statistics. Therefore we generate an output by providing the privacy risk scores and the true labels of the data points for which we computed the privacy risk scores. This output can then be visualized in two separate ways."
      ],
      "id": "FDl3RrF8JZLk"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hmy8hyC4JTaw"
      },
      "source": [
        "# Create user output and plot histogram for train dataset\n",
        "output = UserOutputPrivacyScore(\n",
        "    np.argmax(y_train[:100], axis=1),\n",
        "    train_privacy_risk_score, \n",
        ")"
      ],
      "id": "Hmy8hyC4JTaw",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgj7tBndJdZE"
      },
      "source": [
        "The first way to visualise the privacy risk scores is as a histogram. The histogram shows the distribution of the k-top data points with the highest privacy risk scores per class."
      ],
      "id": "zgj7tBndJdZE"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "7j0g0DcPJe5-",
        "outputId": "3939b522-90c8-4ebb-e7f1-42f730f4247b"
      },
      "source": [
        "# Plot absolut values \n",
        "labels, count = output.histogram_top_k(range(10), 50)"
      ],
      "id": "7j0g0DcPJe5-",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGDmsiYkJgSW"
      },
      "source": [
        "As a second option, you can visualise the privacy risk scores again as a histogram of the distribution of the k-top data points with the highest privacy risk scores per class, but this time the values are relative to the size of respective classe"
      ],
      "id": "AGDmsiYkJgSW"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "zIvg1hJhJiHM",
        "outputId": "23930419-448d-4226-92c9-4e1f9029d06f"
      },
      "source": [
        "# Plot relative values \n",
        "labels, count = output.histogram_top_k_relative(range(10), 50)"
      ],
      "id": "zIvg1hJhJiHM",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDcpMoQpJjkE"
      },
      "source": [
        "#### Explanation of the outcome:\n",
        "\n",
        "##### Vulnerability of individual data points:\n",
        "The training data points that exhibit an increased membership privacy risk might differ from their classes mean samples (outliers) [7]. You could check them again, see if they have the correct label, or if they exhibit any non-standard properties for the class. If so, correct them. It was also shown that points with an high influence on the decision boundary are more vulnerable to membership inference attacks [5]. Therefore, these points might be important. If you want to protect them, you might add several similar training samples as they are to the class. \n",
        "\n",
        "\n",
        "(For References, please see last box)"
      ],
      "id": "uDcpMoQpJjkE"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xG4nYKGzWx7i"
      },
      "source": [
        "### TensorFlow\n",
        "\n",
        "Now we do the same with the TensorFlow model."
      ],
      "id": "xG4nYKGzWx7i"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7ty54AKWx7k"
      },
      "source": [
        "#### Prepare target model\n",
        "\n",
        "Now, we need to initialize our pre-trained Lightweight Deep Convolutional Neural Network (short DCTI) as a generic `Classifier`. Therefore we need to specify the loss function used to train the model (in our case the `tf.keras.losses.CategoricalCrossentropy`), the number of classes and the input shape of our CIFAR-10 dataset."
      ],
      "id": "_7ty54AKWx7k"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uhrn5znOWx7k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8162ec6-d35b-4990-b364-dd30d1dfa5ca"
      },
      "source": [
        "# Initalize TensorFlow target model\n",
        "target_model = Classifier(\n",
        "    tf_dcti.load_dcti(), # TensorFlow DCTI\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(), # Loss function of the TensorFlow target model\n",
        "    nb_classes=TFCIFAR10.N_CLASSES, # Number of classes of the CIFAR10 dataset\n",
        "    input_shape=TFCIFAR10.INPUT_SHAPE # Input shape of the CIFAR10 dataset\n",
        ")"
      ],
      "id": "Uhrn5znOWx7k",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBfeudg_Wx7i"
      },
      "source": [
        "#### Load CIFAR10 Dataset\n",
        "\n",
        "Again, before we can start to conduct the membership inference attacks, we need to load the dataset. The CIFAR10 dataset needs to be preprocessed in a specific manner to work for the TensorFlow model."
      ],
      "id": "UBfeudg_Wx7i"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAJgfSgoWx7j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5bc9052-7c5a-42ae-b392-c49499a6d9d3"
      },
      "source": [
        "# Load CIFAR10 dataset as numpy array\n",
        "x_train, y_train, x_test, y_test = TFCIFAR10.numpy()"
      ],
      "id": "kAJgfSgoWx7j",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLC_hmb8Wx7l"
      },
      "source": [
        "#### Perform Membership Inference Black Box Attack\n",
        "\n",
        "First, we want to attack our target model with the Membership Inference  Black Box Attack. Thus, we initialize the attack with the target model and a dataset used to fit the attack model. The dataset consists of two different sets. The first contains the data (`x_train`) and its corresponding labels (`y_train`) which were used to train the target model. The second contains the data (`x_test`) and its corresponding labels (`y_test`) which were not part of the training process of the target model. After the initialization, we first need to fit the attack model before we can attack the target model. To attack certain data points, we simply input them into the `attack()` method. The result of the attack is an array holding the inferred membership status, 1 indicates a member and 0 indicates non-member."
      ],
      "id": "mLC_hmb8Wx7l"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLddiPbkWx7l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55bbd171-229b-41fd-8a00-8e45ecc4bf03"
      },
      "source": [
        "attack = MembershipInferenceBlackBoxAttack(\n",
        "    target_model, \n",
        "    x_train[:100], \n",
        "    y_train[:100], \n",
        "    x_test[:100], \n",
        "    y_test[:100]\n",
        ")\n",
        "\n",
        "attack.fit()\n",
        "attack.attack(x_train[:100], y_train[:100])"
      ],
      "id": "QLddiPbkWx7l",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0,\n",
              "       1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
              "       0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnE8ETvRWx7m"
      },
      "source": [
        "#### Get machine-readable attack statistics\n",
        "\n",
        "Besides the inferred membership status, we can create more general statistics. To do so, we generate an attack output by providing again the data points which should be attacked and the correct inferred membership labels (in this case all attacked data points are part of the training dataset and thus for all of them a membership should be predicted by the attack model). As result, we get the accuracy, the train-to-test accuracy gap and the train-to-test ratio for the target model and the accuracy for the attack model."
      ],
      "id": "bnE8ETvRWx7m"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysx92hInWx7n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "a8a6f04a-53b4-4c70-82e7-115aea79646d"
      },
      "source": [
        "output = attack.attack_output(\n",
        "    x_train[:100], \n",
        "    y_train[:100], \n",
        "    np.ones((100,))\n",
        ")\n",
        "\n",
        "output.to_json()"
      ],
      "id": "ysx92hInWx7n",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'{\"target_model_train_accuracy\": 0.99, \"target_model_test_accuracy\": 0.91, \"target_model_train_to_test_accuracy_gap\": 0.07999999999999996, \"target_model_train_to_test_accuracy_ratio\": 1.0879120879120878, \"attack_model_accuracy\": 0.75}'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnNgIXJC7ppu"
      },
      "source": [
        "#### Explanation of the outcome:\n",
        "\n",
        "Attack Model Accuracy:\n",
        "The attack model accuracy specifies how well the membership attack model performs in predicting if a given data point was used for training the target model. Since we have a two-class classification problem that the attack model solves (member or non-member), the lowest possible accuracy is 50% (random guessing for each sample). The best accuracy is at 100% if the model predicts every data point is sees right as member or non-member.\n",
        "\n",
        "Train-Test-Gap (difference):\n",
        "If your model has a train-test-gap larger than 5%, this could be a sign that your model overfits. Overfitting can be beneficial for successful membership inference attacks [1]. Therefore, you might want to reduce it by introducing regularization methods in your training, or using specific privacy methods [2,3], such as Differential Privacy [4].\n",
        "\n",
        "(For References, please see last box)\n"
      ],
      "id": "ZnNgIXJC7ppu"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrnYkSK0JqNs"
      },
      "source": [
        "#### Perpare attack analysis\n",
        "\n",
        "Next, we prepare our attack analysis. To initialize our attack analysis we define the Membership Inference Attack method we want to perform (in this case we use the `MembershipInferenceBlackBoxAttack`) and the Attack Input Data. The Attack Input Data consists of two different sets. The first contains the data (`x_train`) and its corresponding labels (`y_train`) which were used to train the target model. The second contains the data (`x_test`) and its corresponding labels (`y_test`) which were not part of the training process of the target model."
      ],
      "id": "mrnYkSK0JqNs"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEyz9CDkJr1Z"
      },
      "source": [
        "analysis = MembershipInferenceAttackAnalysis(\n",
        "    MembershipInferenceBlackBoxAttack, \n",
        "    AttackInputData(\n",
        "        x_train[:100], \n",
        "        y_train[:100], \n",
        "        x_test[:100], \n",
        "        y_test[:100]\n",
        "    )\n",
        ")"
      ],
      "id": "gEyz9CDkJr1Z",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UEL4XUBJtUP"
      },
      "source": [
        "#### Define the slicing\n",
        "\n",
        "Now we can define the slicing for our analysis. The slicing defines how the data will be sliced. Each slice will then be analysed separately. "
      ],
      "id": "9UEL4XUBJtUP"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeGUtkbKJvmv"
      },
      "source": [
        "slicing = Slicing(\n",
        "    entire_dataset=True, \n",
        "    by_class=True, \n",
        "    by_classification_correctness=True\n",
        ")"
      ],
      "id": "YeGUtkbKJvmv",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cT3cZVFFJxJq"
      },
      "source": [
        "#### Perform Membership Inference Attack Analysis\n",
        "\n",
        "Finally, we can perform our Membership Inference Attack Analysis. Therefore, we input the target model, the data that should be analysed, the membership labels (i.e. the labels which correctly describe if a data point is a member of the training dataset or not) and the splicing specification into the `analyse()` method. As a result, we get for each slice the indices of the corresponding data points, a human-readable description of the slice and the advantage score of the Membership Inference Attack (for more details about the advantage score, please read the following paper: https://arxiv.org/abs/1709.01604)."
      ],
      "id": "cT3cZVFFJxJq"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFQuFLedJzEo",
        "outputId": "3a86763a-c4af-4844-c659-800a7eab2211"
      },
      "source": [
        "result = analysis.analyse(\n",
        "    target_model, \n",
        "    np.concatenate((x_train[:100], x_test[:100])), \n",
        "    np.concatenate((y_train[:100], y_test[:100])), \n",
        "    np.concatenate((np.ones(len(x_train[:100])), np.zeros(len(x_test[:100])))), \n",
        "    slicing\n",
        ")\n",
        "\n",
        "print(\"\\n\".join((str(r) for r in result)))"
      ],
      "id": "gFQuFLedJzEo",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MembershipInferenceAttackAnalysisSliceResult(\n",
            "  Slice(\n",
            "    indices: [  0   1 ... 198 199]\n",
            "    desc: Entire dataset\n",
            "  )\n",
            "  advantage: 0.0900\n",
            ")\n",
            "MembershipInferenceAttackAnalysisSliceResult(\n",
            "  Slice(\n",
            "    indices: [  0   1 ... 198 199]\n",
            "    desc: Correctly classified\n",
            "  )\n",
            "  advantage: 0.0004\n",
            ")\n",
            "MembershipInferenceAttackAnalysisSliceResult(\n",
            "  Slice(\n",
            "    indices: [ 84 132 135 137 147 152 157 158 161 178]\n",
            "    desc: Incorrectly classified\n",
            "  )\n",
            "  advantage: 0.3333\n",
            ")\n",
            "MembershipInferenceAttackAnalysisSliceResult(\n",
            "  Slice(\n",
            "    indices: [ 29  30 ... 197 198]\n",
            "    desc: Class=0\n",
            "  )\n",
            "  advantage: 0.1000\n",
            ")\n",
            "MembershipInferenceAttackAnalysisSliceResult(\n",
            "  Slice(\n",
            "    indices: [  4   5 ... 181 182]\n",
            "    desc: Class=1\n",
            "  )\n",
            "  advantage: 0.0000\n",
            ")\n",
            "MembershipInferenceAttackAnalysisSliceResult(\n",
            "  Slice(\n",
            "    indices: [  6  13 ... 184 186]\n",
            "    desc: Class=2\n",
            "  )\n",
            "  advantage: 0.0769\n",
            ")\n",
            "MembershipInferenceAttackAnalysisSliceResult(\n",
            "  Slice(\n",
            "    indices: [  9  17 ... 178 191]\n",
            "    desc: Class=3\n",
            "  )\n",
            "  advantage: 0.2308\n",
            ")\n",
            "MembershipInferenceAttackAnalysisSliceResult(\n",
            "  Slice(\n",
            "    indices: [  3  10 ... 158 194]\n",
            "    desc: Class=4\n",
            "  )\n",
            "  advantage: 0.1818\n",
            ")\n",
            "MembershipInferenceAttackAnalysisSliceResult(\n",
            "  Slice(\n",
            "    indices: [ 27  40 ... 142 185]\n",
            "    desc: Class=5\n",
            "  )\n",
            "  advantage: 0.0000\n",
            ")\n",
            "MembershipInferenceAttackAnalysisSliceResult(\n",
            "  Slice(\n",
            "    indices: [  0  19 ... 195 196]\n",
            "    desc: Class=6\n",
            "  )\n",
            "  advantage: 0.0000\n",
            ")\n",
            "MembershipInferenceAttackAnalysisSliceResult(\n",
            "  Slice(\n",
            "    indices: [  7  11 ... 187 199]\n",
            "    desc: Class=7\n",
            "  )\n",
            "  advantage: 0.1818\n",
            ")\n",
            "MembershipInferenceAttackAnalysisSliceResult(\n",
            "  Slice(\n",
            "    indices: [  8  62 ... 188 192]\n",
            "    desc: Class=8\n",
            "  )\n",
            "  advantage: 0.0000\n",
            ")\n",
            "MembershipInferenceAttackAnalysisSliceResult(\n",
            "  Slice(\n",
            "    indices: [  1   2 ... 176 189]\n",
            "    desc: Class=9\n",
            "  )\n",
            "  advantage: 0.0000\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9n1Y1AuJ0YY"
      },
      "source": [
        "#### Explanation of the outcome:\n",
        "##### Attacker Advantage:\n",
        "The attacker advantageis a score that relies on comparing the model output on member and non-member data points. The model outputs are probability values over all classes, and they are often different on member and non-member data points. Usually, the model is more confident on member data points, because it has seen them during training. When trying to find a threshold value to tell apart member and non-member samples by their different model outputs, the attacker has interest in finding the best ratio between false positives “fpr” (non-members that are classified as members) and true positives “tpr” (members that are correctly identifies as members). \n",
        "\n",
        "This best ratio is calculated as the max(tpr-fpr) over all threshold values and represents the attacker advantage. \n",
        "\n",
        "##### Slicing: Incorrectly classified:\n",
        "It is normal that the attacker is more successful to deduce membership on incorrectly classified samples than on correctly classified ones. This results from the fact, that model predictions are often better on training than on test data points, whereby your attack model might learn to predict incorrectly classified samples as non-members. If your model overfits the training data, this assumption might hold true often enough to make the attack seem more successful on this slice. If you wish to reduce that, pay attention to reducing your model’s overfitting.\n",
        "\n",
        "##### Slicing: Specific classes more vulnerable: \n",
        "It seems that the membership inference attack is more successful on your class X than on the other classes. Research has shown that the class distribution (and also the distribution of data points within one class) are factors that influence the vulnerability of a class for membership inference attacks [5].\n",
        "\n",
        "Also, small classes (belonging to minority groups) can be more prone to membership inference attacks [6]. One reason for this could be, that there is less data for that class, and therefore, the model overfits within this class. It might make sense to look into the vulnerable classes of your model again, and maybe add more data to them, use private synthetic data, or introduce privacy methods like Differential Privacy [6]. Attention, the use of Differential Privacy could have a negative influence on the performance of your model for the minority classes.\n",
        "\n",
        "\n",
        "(For References, please see last box)"
      ],
      "id": "V9n1Y1AuJ0YY"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tiy6rLnLJ3BJ"
      },
      "source": [
        "#### Compute privacy risk score\n",
        "\n",
        "As a next step, we want to compute the privacy risk scores. To do so, we input the target model and the data points which should be evaluated to the respective function. The given data points are separated into a train and tests set. The train set contains of the data (`x_train`) and its corresponding labels (`y_train`) which were used to train the target model. The test set contains the data (`x_test`) and its corresponding labels (`y_test`) which were not part of the training process of the target model. As a result, we get privacy risk scores for each data point, separated into train and test scores. The resulting values indicate the probability of a data point being a member or not."
      ],
      "id": "Tiy6rLnLJ3BJ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ESRttHsJ4iy"
      },
      "source": [
        "# Compute privacy risk score for the TensorFlow target model\n",
        "(\n",
        "    train_privacy_risk_score, \n",
        "    test_privacy_risk_score\n",
        ") = compute_privacy_risk_score(\n",
        "    target_model, \n",
        "    x_train[:100], \n",
        "    y_train[:100], \n",
        "    x_test[:100], \n",
        "    y_test[:100]\n",
        ")"
      ],
      "id": "4ESRttHsJ4iy",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Y_V4NeRJ5oo"
      },
      "source": [
        "#### Get human-readable privacy risk score statistics\n",
        "\n",
        "Besides the privacy risk scores, we can create more human-readable statistics. Therefore we generate an output by providing the privacy risk scores and the true labels of the data points for which we computed the privacy risk scores. This output can then be visualized in two separate ways."
      ],
      "id": "5Y_V4NeRJ5oo"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "io-ALugGJ7K-"
      },
      "source": [
        "# Create user output and plot histogram for train dataset\n",
        "output = UserOutputPrivacyScore(\n",
        "    np.argmax(y_train[:100], axis=1), \n",
        "    train_privacy_risk_score, \n",
        ")"
      ],
      "id": "io-ALugGJ7K-",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_o2JUcg7J8NW"
      },
      "source": [
        "The first way to visualise the privacy risk scores is as a histogram. The histogram shows the distribution of the k-top data points with the highest privacy risk scores per class."
      ],
      "id": "_o2JUcg7J8NW"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "XoeBWIv-J9WL",
        "outputId": "09e48f0a-238e-44da-eabd-a094e024074d"
      },
      "source": [
        "# Plot absolut values \n",
        "labels, count = output.histogram_top_k(range(10), 50)"
      ],
      "id": "XoeBWIv-J9WL",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SxO_JogJ-iy"
      },
      "source": [
        "As a second option, you can visualise the privacy risk scores again as a histogram of the distribution of the k-top data points with the highest privacy risk scores per class, but this time the values are relative to the size of respective classe"
      ],
      "id": "9SxO_JogJ-iy"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "X9XjcpfpJ_oE",
        "outputId": "16d82541-db11-4f57-822e-144fb7c258b9"
      },
      "source": [
        "# Plot relative values \n",
        "labels, count = output.histogram_top_k_relative(range(10), 50)"
      ],
      "id": "X9XjcpfpJ_oE",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJoSOv10KA7d"
      },
      "source": [
        "#### Explanation of the outcome:\n",
        "\n",
        "##### Vulnerability of individual data points:\n",
        "The training data points that exhibit an increased membership privacy risk might differ from their classes mean samples (outliers) [7]. You could check them again, see if they have the correct label, or if they exhibit any non-standard properties for the class. If so, correct them. It was also shown that points with an high influence on the decision boundary are more vulnerable to membership inference attacks [5]. Therefore, these points might be important. If you want to protect them, you might add several similar training samples as they are to the class. \n",
        "\n",
        "\n",
        "(For References, please see last box)"
      ],
      "id": "qJoSOv10KA7d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmyWRprb842M"
      },
      "source": [
        "[1]S. Yeom, I. Giacomelli, M. Fredrikson, and S. Jha. \\Privacy Risk in Machine Learning: Analyzing the Connection to Overfitting\". In: 2018 IEEE 31st Computer Security Foundations Symposium (CSF). July 2018, pp. 268{282. doi:10.1109/CSF.2018.00027.\n",
        "\n",
        "[2] Reza Shokri, Marco Stronati, Congzheng Song, and Vitaly Shmatikov. 2017. Mem-bership Inference Attacks Against Machine Learning Models. In2017 IEEE Sym-posium on Security and Privacy (SP). 3–18.\n",
        "\n",
        "[3] Milad Nasr, Reza Shokri, and Amir Houmansadr. 2018. Machine Learning withMembership Privacy Using Adversarial Regularization. InProceedings of the 2018ACM SIGSAC Conference on Computer and Communications Security(Toronto,Canada)(CCS ’18). Association for Computing Machinery, New York, NY, USA,634–64\n",
        "\n",
        "[4] Cynthia Dwork. 2006.  Differential Privacy. InAutomata, Languages and Pro-gramming, Michele Bugliesi, Bart Preneel, Vladimiro Sassone, and Ingo Wegener(Eds.). Springer Berlin Heidelberg, Berlin, Heidelberg\n",
        "\n",
        "[5] Stacey Truex, Ling Liu, Mehmet Emre Gursoy, Lei Yu, and Wenqi Wei. 2019.Demystifying Membership Inference Attacks in Machine Learning as a Service.IEEE Transactions on Services Computing(2019)\n",
        "\n",
        "[6] Suriyakumar, Vinith M., Nicolas Papernot, Anna Goldenberg, and Marzyeh Ghassemi. \"Chasing Your Long Tails: Differentially Private Prediction in Health Care Settings.\" In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, pp. 723-734. 2021.\n",
        "\n",
        "[7] Yunhui Long, Vincent Bindschaedler, Lei Wang, Diyue Bu, Xiaofeng Wang, HaixuTang, Carl A. Gunter, and Kai Chen. 2018.   Understanding Membership In-ferences on Well-Generalized Learning Models.CoRRabs/1802.04889 (2018).arXiv:1802.04889  http://arxiv.org/abs/1802.0\n"
      ],
      "id": "DmyWRprb842M"
    }
  ]
}