{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvfxnZUWGZ7R"
      },
      "source": [
        "## Demo for Property Inference Attack (PIA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPDjZtZbIZaf"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/privML/privacy-evaluator/blob/feat/138-notebook/notebooks/property_inference_attack.ipynb) [![Open in Github](https://raw.githubusercontent.com/privML/privacy-evaluator/main/notebooks/images/GitHub-Mark-32px.png)](https://github.com/privML/privacy-evaluator/blob/feat/138-notebook/notebooks/property_inference_attack.ipynb)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "t_zNMqFHHUY4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/privML/privacy-evaluator@feat/138-notebook\n",
            "  Cloning https://github.com/privML/privacy-evaluator (to revision feat/138-notebook) to /tmp/pip-req-build-bxx4eomo\n",
            "  Running command git clone -q https://github.com/privML/privacy-evaluator /tmp/pip-req-build-bxx4eomo\n",
            "  Running command git checkout -b feat/138-notebook --track origin/feat/138-notebook\n",
            "  Switched to a new branch 'feat/138-notebook'\n",
            "  Branch 'feat/138-notebook' set up to track remote branch 'feat/138-notebook' from 'origin'.\n",
            "Requirement already satisfied (use --upgrade to upgrade): privacy-evaluator==0.1 from git+https://github.com/privML/privacy-evaluator@feat/138-notebook in /home/ani/.local/lib/python3.8/site-packages\n",
            "Requirement already satisfied: adversarial-robustness-toolbox[pytorch,tensorflow]==1.6.2 in /home/ani/.local/lib/python3.8/site-packages (from privacy-evaluator==0.1) (1.6.2)\n",
            "Requirement already satisfied: matplotlib in /home/ani/.local/lib/python3.8/site-packages (from privacy-evaluator==0.1) (3.4.2)\n",
            "Requirement already satisfied: numpy in /home/ani/.local/lib/python3.8/site-packages (from privacy-evaluator==0.1) (1.20.2)\n",
            "Requirement already satisfied: pandas in /home/ani/.local/lib/python3.8/site-packages (from privacy-evaluator==0.1) (1.2.5)\n",
            "Requirement already satisfied: tensorflow in /home/ani/.local/lib/python3.8/site-packages (from privacy-evaluator==0.1) (2.5.0)\n",
            "Requirement already satisfied: torch in /home/ani/.local/lib/python3.8/site-packages (from privacy-evaluator==0.1) (1.9.0)\n",
            "Requirement already satisfied: torchvision in /home/ani/.local/lib/python3.8/site-packages (from privacy-evaluator==0.1) (0.10.0)\n",
            "Requirement already satisfied: tqdm in /home/ani/.local/lib/python3.8/site-packages (from adversarial-robustness-toolbox[pytorch,tensorflow]==1.6.2->privacy-evaluator==0.1) (4.61.1)\n",
            "Requirement already satisfied: scikit-learn<0.24.3,>=0.22.2 in /home/ani/.local/lib/python3.8/site-packages (from adversarial-robustness-toolbox[pytorch,tensorflow]==1.6.2->privacy-evaluator==0.1) (0.24.2)\n",
            "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from adversarial-robustness-toolbox[pytorch,tensorflow]==1.6.2->privacy-evaluator==0.1) (1.14.0)\n",
            "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from adversarial-robustness-toolbox[pytorch,tensorflow]==1.6.2->privacy-evaluator==0.1) (45.2.0)\n",
            "Requirement already satisfied: numba~=0.53.1 in /home/ani/.local/lib/python3.8/site-packages (from adversarial-robustness-toolbox[pytorch,tensorflow]==1.6.2->privacy-evaluator==0.1) (0.53.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /home/ani/.local/lib/python3.8/site-packages (from adversarial-robustness-toolbox[pytorch,tensorflow]==1.6.2->privacy-evaluator==0.1) (1.7.0)\n",
            "Requirement already satisfied: h5py; extra == \"tensorflow\" in /home/ani/.local/lib/python3.8/site-packages (from adversarial-robustness-toolbox[pytorch,tensorflow]==1.6.2->privacy-evaluator==0.1) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-addons; extra == \"tensorflow\" in /home/ani/.local/lib/python3.8/site-packages (from adversarial-robustness-toolbox[pytorch,tensorflow]==1.6.2->privacy-evaluator==0.1) (0.13.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /home/ani/.local/lib/python3.8/site-packages (from matplotlib->privacy-evaluator==0.1) (2.8.1)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /home/ani/.local/lib/python3.8/site-packages (from matplotlib->privacy-evaluator==0.1) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/ani/.local/lib/python3.8/site-packages (from matplotlib->privacy-evaluator==0.1) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ani/.local/lib/python3.8/site-packages (from matplotlib->privacy-evaluator==0.1) (1.3.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/lib/python3/dist-packages (from matplotlib->privacy-evaluator==0.1) (7.0.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /home/ani/.local/lib/python3.8/site-packages (from pandas->privacy-evaluator==0.1) (2021.1)\n",
            "Requirement already satisfied: gast==0.4.0 in /home/ani/.local/lib/python3.8/site-packages (from tensorflow->privacy-evaluator==0.1) (0.4.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /home/ani/.local/lib/python3.8/site-packages (from tensorflow->privacy-evaluator==0.1) (1.1.0)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /home/ani/.local/lib/python3.8/site-packages (from tensorflow->privacy-evaluator==0.1) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /home/ani/.local/lib/python3.8/site-packages (from tensorflow->privacy-evaluator==0.1) (0.2.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /home/ani/.local/lib/python3.8/site-packages (from tensorflow->privacy-evaluator==0.1) (0.13.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /home/ani/.local/lib/python3.8/site-packages (from tensorflow->privacy-evaluator==0.1) (3.17.3)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /home/ani/.local/lib/python3.8/site-packages (from tensorflow->privacy-evaluator==0.1) (1.6.3)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /home/ani/.local/lib/python3.8/site-packages (from tensorflow->privacy-evaluator==0.1) (1.34.1)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /home/ani/.local/lib/python3.8/site-packages (from tensorflow->privacy-evaluator==0.1) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /home/ani/.local/lib/python3.8/site-packages (from tensorflow->privacy-evaluator==0.1) (3.7.4.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /home/ani/.local/lib/python3.8/site-packages (from tensorflow->privacy-evaluator==0.1) (2.5.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /home/ani/.local/lib/python3.8/site-packages (from tensorflow->privacy-evaluator==0.1) (1.1.2)\n",
            "Requirement already satisfied: wheel~=0.35 in /home/ani/.local/lib/python3.8/site-packages (from tensorflow->privacy-evaluator==0.1) (0.36.2)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /home/ani/.local/lib/python3.8/site-packages (from tensorflow->privacy-evaluator==0.1) (3.3.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /home/ani/.local/lib/python3.8/site-packages (from tensorflow->privacy-evaluator==0.1) (1.12.1)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /home/ani/.local/lib/python3.8/site-packages (from tensorflow->privacy-evaluator==0.1) (1.12)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ani/.local/lib/python3.8/site-packages (from scikit-learn<0.24.3,>=0.22.2->adversarial-robustness-toolbox[pytorch,tensorflow]==1.6.2->privacy-evaluator==0.1) (2.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /home/ani/.local/lib/python3.8/site-packages (from scikit-learn<0.24.3,>=0.22.2->adversarial-robustness-toolbox[pytorch,tensorflow]==1.6.2->privacy-evaluator==0.1) (1.0.1)\n",
            "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in /home/ani/.local/lib/python3.8/site-packages (from numba~=0.53.1->adversarial-robustness-toolbox[pytorch,tensorflow]==1.6.2->privacy-evaluator==0.1) (0.36.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /home/ani/.local/lib/python3.8/site-packages (from tensorflow-addons; extra == \"tensorflow\"->adversarial-robustness-toolbox[pytorch,tensorflow]==1.6.2->privacy-evaluator==0.1) (2.12.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/ani/.local/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow->privacy-evaluator==0.1) (1.8.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/ani/.local/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow->privacy-evaluator==0.1) (1.32.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /home/ani/.local/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow->privacy-evaluator==0.1) (3.3.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3/dist-packages (from tensorboard~=2.5->tensorflow->privacy-evaluator==0.1) (2.22.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/ani/.local/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow->privacy-evaluator==0.1) (0.4.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /home/ani/.local/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow->privacy-evaluator==0.1) (2.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/ani/.local/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow->privacy-evaluator==0.1) (0.6.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /home/ani/.local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->privacy-evaluator==0.1) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/ani/.local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->privacy-evaluator==0.1) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ani/.local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->privacy-evaluator==0.1) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ani/.local/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow->privacy-evaluator==0.1) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /home/ani/.local/lib/python3.8/site-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->privacy-evaluator==0.1) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow->privacy-evaluator==0.1) (3.1.0)\n",
            "Building wheels for collected packages: privacy-evaluator\n",
            "  Building wheel for privacy-evaluator (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for privacy-evaluator: filename=privacy_evaluator-0.1-py3-none-any.whl size=37905 sha256=ed5a14d84dc53aef52402c4553f0017e89a4ad9c6451ea0dc5879c1d532555df\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-d6w_xkb5/wheels/1d/77/15/ddd4af0b777ef8ed6440faba0cbf4033350e1b18270a379ada\n",
            "Successfully built privacy-evaluator\n"
          ]
        }
      ],
      "source": [
        "!pip3 install git+https://github.com/privML/privacy-evaluator@feat/138-notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "10607993"
      },
      "outputs": [],
      "source": [
        "from privacy_evaluator.attacks.property_inference_attack import PropertyInferenceAttack\n",
        "from privacy_evaluator.classifiers.classifier import Classifier\n",
        "from privacy_evaluator.utils.data_utils import (\n",
        "    dataset_downloader,\n",
        "    new_dataset_from_size_dict,\n",
        ")\n",
        "from privacy_evaluator.utils.trainer import trainer\n",
        "from privacy_evaluator.models.torch.cnn import ConvNet\n",
        "\n",
        "import collections\n",
        "from matplotlib import pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hedtyyE_GZ7Z"
      },
      "source": [
        "\n",
        "# Property Inference Attack on MNIST Dataset\n",
        "\n",
        "## 1. Overview of the Dataset\n",
        "\n",
        "MNIST is a dataset of black-and-white handwritten digits from 10 classes (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), consisting of 60000 training- and 10000 test-images.\n",
        "\n",
        "The size of each image is $28\\times 28 \\times 1$:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jt71upsQGZ7a",
        "outputId": "df64070d-e7c1-48cd-db94-e6632f5d0ce0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(28, 28, 1)\n"
          ]
        }
      ],
      "source": [
        "train_dataset, test_dataset = dataset_downloader(\"MNIST\")\n",
        "input_shape = test_dataset[0][0].shape\n",
        "print(input_shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaZ15iLZGZ7c"
      },
      "source": [
        "As of now we can only perform binary attacks. Therefore as an example we use classes 0 and 1 from MNIST.\n",
        "\n",
        "We choose a sample size for each class (on which we train the target model):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "WmHrXo7QGZ7d"
      },
      "outputs": [],
      "source": [
        "NUM_ELEMENTS_PER_CLASSES = {0: 1000, 1: 500}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrCu1SZzGZ7e"
      },
      "source": [
        "And then adjust the training set accordingly:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfqQFdCIGZ7e",
        "outputId": "7b637906-a182-476f-ccdc-769dcaeab06d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1500, 28, 28, 1) (1500,)\n"
          ]
        }
      ],
      "source": [
        "train_set = new_dataset_from_size_dict(train_dataset, NUM_ELEMENTS_PER_CLASSES)\n",
        "print(train_set[0].shape, train_set[1].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2IFaCSoGZ7f"
      },
      "source": [
        "## 2. Load and train your target model\n",
        "\n",
        "Load *your* personal target model in the next cell to perform the attack on it. Any PyTorch or TensorFlow model can be used.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Rr4BA37yGZ7i"
      },
      "outputs": [],
      "source": [
        "# For demonstration purposes we load the following ConvNet model for two input classes\n",
        "# (multi-class input will be supported in future releases):\n",
        "\n",
        "num_classes = len(NUM_ELEMENTS_PER_CLASSES)\n",
        "\n",
        "model = ConvNet(num_classes, input_shape, num_channels=(input_shape[-1], 16, 32, 64))  ### <--- Customize this line"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Ds3forQVGZ7j"
      },
      "outputs": [],
      "source": [
        "trainer(train_set, NUM_ELEMENTS_PER_CLASSES, model, num_epochs=8)\n",
        "\n",
        "# Convert to ART classifier\n",
        "\n",
        "target_model = Classifier._to_art_classifier(model, num_classes, input_shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gG36p_-IGZ7k"
      },
      "source": [
        "## 3. Perform attack\n",
        "\n",
        "Each attack consists of several sub-attack (one for each element in \"ratios_for_attack\").\n",
        "\n",
        "In a sub-attack we create a number of shadow classifiers of the same architecture as the provided target model. \n",
        "\n",
        "Half of them will be trained on an unbalanced data set of the given ratio, the other half is trained on blanced data sets.\n",
        "\n",
        "The shadow classifiers serve as training set for a meta classifier, which finally predicts the likelihood of the target model to have a given property (i.e. the ratio)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "qNThcpLfGZ7k"
      },
      "outputs": [],
      "source": [
        "# Number of shadow classifiers (increase for better accuracy of the meta classifier, decrease when not enough computing power is available.)\n",
        "amount_sets = 1000 # needs to be even\n",
        "\n",
        "# Size of data set to train the shadow classifiers\n",
        "size_set = 100\n",
        "\n",
        "# Ratios to perform the attack for (the real ratios of our example target model is 0.66: {0: 1000, 1: 500}: 66% of data points are from class 0, 33% from class 1.)\n",
        "ratios_for_attack = [0.66,0.33]\n",
        "classes = [0,1]\n",
        "\n",
        "attack = PropertyInferenceAttack(target_model, train_set, verbose=1, size_set=size_set, \\\n",
        "    ratios_for_attack=ratios_for_attack, classes=classes,amount_sets=amount_sets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3aihZM-GZ7l",
        "outputId": "99216e1b-7da5-427b-f20e-1531275ce0e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initiating Property Inference Attack ... \n",
            "Extracting features from target model ... \n",
            "(97634,)  --- features extracted from the target model.\n",
            "Creating set of 500 balanced shadow classifiers ... \n",
            "Creating shadow training sets\n",
            "Training shadow classifiers\n",
            "Performing PIA for various ratios ... \n",
            "  0%|          | 0/2 [00:00<?, ?it/s]Creating shadow training sets\n",
            "Training shadow classifiers\n",
            "Epoch 1/2\n",
            "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_train_function.<locals>.train_function at 0x7f9f3140b290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "8/8 [==============================] - 302s 36s/step - loss: 1.0421 - accuracy: 0.4980\n",
            "Epoch 2/2\n",
            "8/8 [==============================] - 308s 39s/step - loss: 0.9992 - accuracy: 0.5250\n",
            " 50%|█████     | 1/2 [10:41<10:41, 641.89s/it]Creating shadow training sets\n",
            "Training shadow classifiers\n",
            "Epoch 1/2\n",
            "8/8 [==============================] - 325s 39s/step - loss: 1.0286 - accuracy: 0.5140\n",
            "Epoch 2/2\n",
            "8/8 [==============================] - 320s 40s/step - loss: 0.9838 - accuracy: 0.5080\n",
            "100%|██████████| 2/2 [21:37<00:00, 648.97s/it]\n"
          ]
        }
      ],
      "source": [
        "output = attack.attack()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vokop1MmGZ7l",
        "outputId": "36a8d0be-4447-40c2-bb1e-6e27b450e84f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('The most probable property is class 0: 0.67, class 1: 0.33 with a probability of 0.48981621861457825.',\n",
              " {'class 0: 0.67, class 1: 0.33': 0.48981622,\n",
              "  'class 0: 0.34, class 1: 0.66': 0.48211873})"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Jf9lG3ZGZ7m"
      },
      "source": [
        "## Human readable output of the attack:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "T2jl8mO7GZ7m",
        "outputId": "5f441506-c0bb-4dab-c497-19431b1104d5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The most probable property is class 0: 0.67, class 1: 0.33 with a probability of 0.48981621861457825.'"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output[0]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "property_inference_attack.py.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "fd69f43f58546b570e94fd7eba7b65e6bcc7a5bbc4eab0408017d18902915d69"
    },
    "kernelspec": {
      "display_name": "Python 3.7.10 64-bit",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": ""
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}