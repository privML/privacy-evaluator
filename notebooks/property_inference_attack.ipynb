{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvfxnZUWGZ7R"
      },
      "source": [
        "# Demo for Property Inference Attack (PIA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPDjZtZbIZaf"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/privML/privacy-evaluator/blob/team2sprint4/notebooks/property_inference_attack.ipynb) [![Open in Github](https://raw.githubusercontent.com/privML/privacy-evaluator/main/notebooks/images/GitHub-Mark-32px.png)](https://github.com/privML/privacy-evaluator/blob/team2sprint4/notebooks/property_inference_attack.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Overview\n",
        "In this notebook, we want to show you how to use the privacy-evaluator tool to perform the Property Inference Attack on a provided Pytorch model trained with the MNIST dataset. \\\n",
        "The goal of the Property Inference Attack is to find out whether the training dataset of a given model has a specific property (for more detailed information about the property inference attack take a look at [this paper](https://dl.acm.org/doi/pdf/10.1145/3243734.3243834) or at [Youtube](https://www.youtube.com/watch?v=99YHPIsKzCc&)).\n",
        "\n",
        "\n",
        "![Property_Inference_Attack](https://i.imgur.com/IX1M3TX.png)\n",
        "\n",
        "\n",
        "In our example the property we're trying to find out is the class distribution of the training dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "First, you should set the notebook's runtime to use a GPU (e.g. if Colab is used go to ***Runtime > Change runtime type > Hardware accelerator***). Now we can install the `privacy-evaluator` package and import all needed modules."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "t_zNMqFHHUY4",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/privML/privacy-evaluator@team2sprint4\n",
            "  Cloning https://github.com/privML/privacy-evaluator (to revision team2sprint4) to /tmp/pip-req-build-lr7lmz7q\n",
            "  Running command git clone -q https://github.com/privML/privacy-evaluator /tmp/pip-req-build-lr7lmz7q\n",
            "  Running command git checkout -b team2sprint4 --track origin/team2sprint4\n",
            "  Switched to a new branch 'team2sprint4'\n",
            "  Branch 'team2sprint4' set up to track remote branch 'team2sprint4' from 'origin'.\n",
            "Requirement already satisfied (use --upgrade to upgrade): privacy-evaluator==0.1 from git+https://github.com/privML/privacy-evaluator@team2sprint4 in /home/ani/.local/lib/python3.8/site-packages\n",
            "Requirement already satisfied: adversarial-robustness-toolbox[pytorch,tensorflow]==1.6.2 in /home/ani/.local/lib/python3.8/site-packages (from privacy-evaluator==0.1) (1.6.2)\n",
            "Requirement already satisfied: matplotlib in /home/ani/.local/lib/python3.8/site-packages (from privacy-evaluator==0.1) (3.4.2)\n",
            "Requirement already satisfied: numpy in /home/ani/.local/lib/python3.8/site-packages (from privacy-evaluator==0.1) (1.20.2)\n",
            "Requirement already satisfied: pandas in /home/ani/.local/lib/python3.8/site-packages (from privacy-evaluator==0.1) (1.2.5)\n",
            "Requirement already satisfied: tensorflow in /home/ani/.local/lib/python3.8/site-packages (from privacy-evaluator==0.1) (2.5.0)\n",
            "Requirement already satisfied: torch in /home/ani/.local/lib/python3.8/site-packages (from privacy-evaluator==0.1) (1.9.0)\n",
            "Requirement already satisfied: torchvision in /home/ani/.local/lib/python3.8/site-packages (from privacy-evaluator==0.1) (0.10.0)\n",
            "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from adversarial-robustness-toolbox[pytorch,tensorflow]==1.6.2->privacy-evaluator==0.1) (1.14.0)\n",
            "Requirement already satisfied: tqdm in /home/ani/.local/lib/python3.8/site-packages (from adversarial-robustness-toolbox[pytorch,tensorflow]==1.6.2->privacy-evaluator==0.1) (4.61.1)\n",
            "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from adversarial-robustness-toolbox[pytorch,tensorflow]==1.6.2->privacy-evaluator==0.1) (45.2.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /home/ani/.local/lib/python3.8/site-packages (from adversarial-robustness-toolbox[pytorch,tensorflow]==1.6.2->privacy-evaluator==0.1) (1.7.0)\n",
            "Requirement already satisfied: scikit-learn<0.24.3,>=0.22.2 in /home/ani/.local/lib/python3.8/site-packages (from adversarial-robustness-toolbox[pytorch,tensorflow]==1.6.2->privacy-evaluator==0.1) (0.24.2)\n",
            "Requirement already satisfied: numba~=0.53.1 in /home/ani/.local/lib/python3.8/site-packages (from adversarial-robustness-toolbox[pytorch,tensorflow]==1.6.2->privacy-evaluator==0.1) (0.53.1)\n",
            "Requirement already satisfied: tensorflow-addons; extra == \"tensorflow\" in /home/ani/.local/lib/python3.8/site-packages (from adversarial-robustness-toolbox[pytorch,tensorflow]==1.6.2->privacy-evaluator==0.1) (0.13.0)\n",
            "Requirement already satisfied: h5py; extra == \"tensorflow\" in /home/ani/.local/lib/python3.8/site-packages (from adversarial-robustness-toolbox[pytorch,tensorflow]==1.6.2->privacy-evaluator==0.1) (3.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /home/ani/.local/lib/python3.8/site-packages (from matplotlib->privacy-evaluator==0.1) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /home/ani/.local/lib/python3.8/site-packages (from matplotlib->privacy-evaluator==0.1) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ani/.local/lib/python3.8/site-packages (from matplotlib->privacy-evaluator==0.1) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/ani/.local/lib/python3.8/site-packages (from matplotlib->privacy-evaluator==0.1) (0.10.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/lib/python3/dist-packages (from matplotlib->privacy-evaluator==0.1) (7.0.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /home/ani/.local/lib/python3.8/site-packages (from pandas->privacy-evaluator==0.1) (2021.1)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /home/ani/.local/lib/python3.8/site-packages (from tensorflow->privacy-evaluator==0.1) (2.5.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /home/ani/.local/lib/python3.8/site-packages (from tensorflow->privacy-evaluator==0.1) (0.2.0)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /home/ani/.local/lib/python3.8/site-packages (from tensorflow->privacy-evaluator==0.1) (1.34.1)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /home/ani/.local/lib/python3.8/site-packages (from tensorflow->privacy-evaluator==0.1) (1.6.3)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /home/ani/.local/lib/python3.8/site-packages (from tensorflow->privacy-evaluator==0.1) (1.1.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /home/ani/.local/lib/python3.8/site-packages (from tensorflow->privacy-evaluator==0.1) (0.36.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /home/ani/.local/lib/python3.8/site-packages (from tensorflow->privacy-evaluator==0.1) (3.17.3)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /home/ani/.local/lib/python3.8/site-packages (from tensorflow->privacy-evaluator==0.1) (1.12)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /home/ani/.local/lib/python3.8/site-packages (from tensorflow->privacy-evaluator==0.1) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /home/ani/.local/lib/python3.8/site-packages (from tensorflow->privacy-evaluator==0.1) (1.1.2)\n",
            "Requirement already satisfied: absl-py~=0.10 in /home/ani/.local/lib/python3.8/site-packages (from tensorflow->privacy-evaluator==0.1) (0.13.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /home/ani/.local/lib/python3.8/site-packages (from tensorflow->privacy-evaluator==0.1) (3.7.4.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /home/ani/.local/lib/python3.8/site-packages (from tensorflow->privacy-evaluator==0.1) (2.5.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /home/ani/.local/lib/python3.8/site-packages (from tensorflow->privacy-evaluator==0.1) (1.12.1)\n",
            "Requirement already satisfied: gast==0.4.0 in /home/ani/.local/lib/python3.8/site-packages (from tensorflow->privacy-evaluator==0.1) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /home/ani/.local/lib/python3.8/site-packages (from tensorflow->privacy-evaluator==0.1) (3.3.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /home/ani/.local/lib/python3.8/site-packages (from scikit-learn<0.24.3,>=0.22.2->adversarial-robustness-toolbox[pytorch,tensorflow]==1.6.2->privacy-evaluator==0.1) (1.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ani/.local/lib/python3.8/site-packages (from scikit-learn<0.24.3,>=0.22.2->adversarial-robustness-toolbox[pytorch,tensorflow]==1.6.2->privacy-evaluator==0.1) (2.1.0)\n",
            "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in /home/ani/.local/lib/python3.8/site-packages (from numba~=0.53.1->adversarial-robustness-toolbox[pytorch,tensorflow]==1.6.2->privacy-evaluator==0.1) (0.36.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /home/ani/.local/lib/python3.8/site-packages (from tensorflow-addons; extra == \"tensorflow\"->adversarial-robustness-toolbox[pytorch,tensorflow]==1.6.2->privacy-evaluator==0.1) (2.12.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /home/ani/.local/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow->privacy-evaluator==0.1) (2.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/ani/.local/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow->privacy-evaluator==0.1) (1.32.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/ani/.local/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow->privacy-evaluator==0.1) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /home/ani/.local/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow->privacy-evaluator==0.1) (3.3.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3/dist-packages (from tensorboard~=2.5->tensorflow->privacy-evaluator==0.1) (2.22.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/ani/.local/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow->privacy-evaluator==0.1) (1.8.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/ani/.local/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow->privacy-evaluator==0.1) (0.4.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /home/ani/.local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->privacy-evaluator==0.1) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/ani/.local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->privacy-evaluator==0.1) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ani/.local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->privacy-evaluator==0.1) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ani/.local/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow->privacy-evaluator==0.1) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /home/ani/.local/lib/python3.8/site-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->privacy-evaluator==0.1) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow->privacy-evaluator==0.1) (3.1.0)\n",
            "Building wheels for collected packages: privacy-evaluator\n",
            "  Building wheel for privacy-evaluator (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for privacy-evaluator: filename=privacy_evaluator-0.1-py3-none-any.whl size=28617451 sha256=225d1f485fe65bef4bce0eec03c74fe177d8cadb791a6e7af093effe2db427a6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-yci7dner/wheels/17/a8/12/f05e8cd0aa70c8b9696e12d21946242d012c4ba1d6b54d9d6c\n",
            "Successfully built privacy-evaluator\n"
          ]
        }
      ],
      "source": [
        "!pip3 install git+https://github.com/privML/privacy-evaluator@team2sprint4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "10607993"
      },
      "outputs": [],
      "source": [
        "from privacy_evaluator.attacks.property_inference_attack import PropertyInferenceAttack\n",
        "from privacy_evaluator.classifiers.classifier import Classifier\n",
        "from privacy_evaluator.utils.data_utils import (\n",
        "    dataset_downloader,\n",
        "    new_dataset_from_size_dict,\n",
        ")\n",
        "from privacy_evaluator.utils.trainer import trainer\n",
        "from privacy_evaluator.models.torch.cnn import ConvNet\n",
        "\n",
        "import collections\n",
        "from matplotlib import pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hedtyyE_GZ7Z"
      },
      "source": [
        "\n",
        "# Conduct Property Inference Attack\n",
        "Now we can start with conducting the Property Inference Attack.\n",
        "\n",
        "\n",
        "## 1.1 Overview of the dataset\n",
        "We will work with the MNIST dataset.\\\n",
        "MNIST is a dataset of black-and-white handwritten digits from 10 classes (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), consisting of 60000 training- and 10000 test-images.\\\n",
        "You can see some sample images of the MNIST dataset printed below.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 576x576 with 3 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Print images\n",
        "images = test_dataset[0][:3]\n",
        "_, axs = plt.subplots(1, 3, figsize=(8, 8))\n",
        "axs = axs.flatten()\n",
        "for image, ax in zip(images, axs):\n",
        "    ax.imshow(image, cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.2 Download of the dataset\n",
        "\n",
        "First, we download the MNIST dataset.\\\n",
        "The size of each image is $28\\times 28 \\times 1$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jt71upsQGZ7a",
        "outputId": "df64070d-e7c1-48cd-db94-e6632f5d0ce0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input shape of images: (28, 28, 1)\n"
          ]
        }
      ],
      "source": [
        "train_dataset, test_dataset = dataset_downloader(\"MNIST\")\n",
        "input_shape = test_dataset[0][0].shape\n",
        "print(f\"Input shape of images: {input_shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaZ15iLZGZ7c"
      },
      "source": [
        "## 1.3 Adjustment of dataset to binary attack\n",
        "As of now, we can only perform binary attacks.\\\n",
        "A binary attack is a attack, where the target model is only classifying into 2 different classes.\\\n",
        "This means that the dataset the target model is trained on only contain two different classes. For our example we therefore use classes 0 and 1 from MNIST, which represent the digits 0 and 1.\n",
        "\n",
        "We specify a distribution of these two classes (`NUM_ELEMENTS_PER_CLASSES`) and adjust the MNIST dataset accordingly. \\\n",
        "On this adjusted dataset we will train our target model and later the attacks goal is to predict this distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "WmHrXo7QGZ7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Amount of images per class: {0: 1000, 1: 500}\n",
            "Amount of images in total: (1500,)\n",
            "Size of each image: (28, 28, 1)\n"
          ]
        }
      ],
      "source": [
        "NUM_ELEMENTS_PER_CLASSES = {0: 1000, 1: 500}\n",
        "train_set = new_dataset_from_size_dict(train_dataset, NUM_ELEMENTS_PER_CLASSES)\n",
        "print(f\"Amount of images per class: {NUM_ELEMENTS_PER_CLASSES}\")\n",
        "print(f\"Amount of images in total: {train_set[1].shape}\")\n",
        "print(f\"Size of each image: {train_set[0][0].shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2IFaCSoGZ7f"
      },
      "source": [
        "## 2. Load and train target model\n",
        "We now load our target model.\\\n",
        "We use a convolutional neural network (CNN) and train it on the dataset created in the step before. \\\n",
        "We then convert it to an ART classifier to make it compatible with the [Adversial Robustness Toolbox](https://github.com/Trusted-AI/adversarial-robustness-toolbox). This step is not important to understand for the actual attack but might be interesting to know for you if know the ART.\n",
        "\n",
        "Our target model is now all set for the actual attack on it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Rr4BA37yGZ7i"
      },
      "outputs": [],
      "source": [
        "num_classes = len(NUM_ELEMENTS_PER_CLASSES)\n",
        "model = ConvNet(num_classes, input_shape, num_channels=(input_shape[-1], 16, 32, 64))\n",
        "trainer(train_set, NUM_ELEMENTS_PER_CLASSES, model, num_epochs=8)\n",
        "\n",
        "# Convert to ART classifier\n",
        "\n",
        "target_model = Classifier._to_art_classifier(model, \"sparse_categorical_crossentropy\", num_classes, input_shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gG36p_-IGZ7k"
      },
      "source": [
        "## 3. Perform attack\n",
        "\n",
        "### 3.1 Overview over whole attack\n",
        "One property inference attack consists of several property inference sub-attacks for different distributions of the training data. One subattack is running for one ratio (e.g. 66% class 0, 34% class 1) and predicts whether it's more likely that the distribution of the training data of the target model was according to this special ratio or a balanced distribution (50% class 0, 50% class 1). \\\n",
        "We specify the ratios in `ratios_for_attack`. We only specify one ratio for class 0 in the list, the other one for class 1 is automatically computed in the attack (1 - ratio for class 0). \\\n",
        "The whole attack then checks, which distribution of the subattacks has the highest probability.\n",
        "\n",
        "![Property_Inference_Attack_overview](https://i.imgur.com/yHPc8bO.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Overview over a subattack\n",
        "In every subattack we create a number of shadow classifiers of the same architecture as the provided target model.\n",
        "\n",
        "![shadow_classifiers](https://i.imgur.com/vffpROO.jpg)\n",
        "\n",
        "Half of the shadow classifiers will be trained on an unbalanced data set of the given ratio (e.g. 70% class 0, 30% class 1) - our property -, the other half is trained on a balanced data sets (50% class 0, 50% class 1) - our negation of property.\n",
        "\n",
        "![shadow_training_sets](https://i.imgur.com/ryUDdbK.jpg)\n",
        "\n",
        "Once created and trained, the features of the shadow classifiers are extracted. Generally speaking, the extracted features are nothing more than on what specifics of the image the model determined its prediction. \\\n",
        "The extracted features are then the training data for the meta classifier. This means that the meta classifier is trained to distinguish between the property and the negation of property (unbalanced with specific ratio vs. balanced).\n",
        "\n",
        "![meta_classifier](https://i.imgur.com/mhpkRm2.jpg)\n",
        "\n",
        "Hence, the meta classifier gets as an input the feature extraction of the target model. \n",
        "\n",
        "If the data set used for the target model does indeed follow the property (unbalanced with specific ratio), the extracted features of the target model will show simularities to the feature extractions of the shadow classifiers trained on data sets that follow the property. Thus, the meta classifier will predict in this case that the likelihood of the target model to have the given property is higher than it having the negation of the property (similar procedure in the opposite case that the data set of the target model follows the negation of the property). \n",
        "\n",
        "To conclude, the meta classifier is the model which finally predicts the likelihood of the target model to have a given property (i.e. the ratio).\n",
        "\n",
        "![prediction](https://i.imgur.com/Skf8j7S.jpg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3 Perform actual attack\n",
        "We first define the `number_of_shadow_classifiers`. In `size_set` we define the size of the training data sets for each shadow classifier. For both parameters we chose a really small numbers due to runtime issues, but for a real attack <1000 shadow classifiers are not recommended and also the size set should be increased according to the size of the dataset you're sampling from. In the case of MNIST set sizes between 500 and 1500 are reasonable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "qNThcpLfGZ7k"
      },
      "outputs": [],
      "source": [
        "# Number of shadow classifiers (increase for better accuracy of the meta classifier, decrease when not enough computing power is available.)\n",
        "number_of_shadow_classifiers = 2 #needs to be even\n",
        "\n",
        "# Size of data set to train the shadow classifiers\n",
        "size_set = 6\n",
        "#Ratios to perform the attack for (the real ratios of our example target model is 0.66: {0: 1000, 1: 500}: 66% of data points are from class 0, 33% from class 1.)\n",
        "ratios_for_attack = [0.66,0.05]\n",
        "classes = [0,1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we perform the attack and safe the output in the variable `output`. The output consists of two elements. One is a string with a message where the actual prediction is printed. The other one is a dictionary where for every ratio specified before in `ratios_for attack` we get the likelihood that the training set was this ratio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3aihZM-GZ7l",
        "outputId": "99216e1b-7da5-427b-f20e-1531275ce0e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initiating Property Inference Attack ... \n",
            "Extracting features from target model ... \n",
            "(97634,)  --- features extracted from the target model.\n",
            "Creating set of 1 balanced shadow classifiers ... \n",
            "Creating shadow training sets\n",
            "Training shadow classifiers\n",
            "Performing PIA for various ratios ... \n",
            "  0%|          | 0/2 [00:00<?, ?it/s]Creating shadow training sets\n",
            "Training shadow classifiers\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 24s 24s/step - loss: 0.3359 - accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.2144 - accuracy: 0.0000e+00\n",
            " 50%|█████     | 1/2 [00:44<00:44, 44.19s/it]Creating shadow training sets\n",
            "Training shadow classifiers\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 24s 24s/step - loss: 0.2151 - accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.0761 - accuracy: 0.0000e+00\n",
            "100%|██████████| 2/2 [01:11<00:00, 35.62s/it]\n"
          ]
        }
      ],
      "source": [
        "attack = PropertyInferenceAttack(target_model, train_set, verbose=1, size_set=size_set, \\\n",
        "    ratios_for_attack=ratios_for_attack, classes=classes,amount_sets=number_of_shadow_classifiers)\n",
        "output = attack.attack()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vokop1MmGZ7l",
        "outputId": "36a8d0be-4447-40c2-bb1e-6e27b450e84f"
      },
      "source": [
        "The human readable output message is the string, it gives us the actual prediction:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The most probable property is class 0: 0.95, class 1: 0.05 with a probability of 0.50660240650177.'"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And the more detailed output you could use for visualization or further analysis is the dictionary.\n",
        "If all the probabilities are close to 0.5 and none is standing out significantly from all the others you could try using more shadow classifiers (= make the training set for the meta classifier larger)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'class 0: 0.95, class 1: 0.05': 0.5066024,\n",
              " 'class 0: 0.34, class 1: 0.66': 0.492016}"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "property_inference_attack.py.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": ""
    },
    "metadata": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}