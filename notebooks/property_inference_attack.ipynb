{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvfxnZUWGZ7R"
      },
      "source": [
        "# Demo for Property Inference Attack (PIA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPDjZtZbIZaf"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/privML/privacy-evaluator/blob/team2sprint4/notebooks/property_inference_attack.ipynb) [![Open in Github](https://raw.githubusercontent.com/privML/privacy-evaluator/main/notebooks/images/GitHub-Mark-32px.png)](https://github.com/privML/privacy-evaluator/blob/team2sprint4/notebooks/property_inference_attack.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Overview\n",
        "In this notebook, we want to show you how to use the privacy-evaluator tool to perform the Property Inference Attack on a provided Pytorch model trained with the MNIST dataset. \\\n",
        "The goal of the Property Inference Attack is to find out whether the training dataset of a given model has a specific property (for more detailed information about the property inference attack take a look at [this paper](https://dl.acm.org/doi/pdf/10.1145/3243734.3243834) or at [Youtube](https://www.youtube.com/watch?v=99YHPIsKzCc&)).\n",
        "\n",
        "\n",
        "![Property_Inference_Attack](https://i.imgur.com/IX1M3TX.png)\n",
        "\n",
        "\n",
        "In our example the property we're trying to find out is the class distribution of the training dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "First, you should set the notebook's runtime to use a GPU (e.g. if Colab is used go to ***Runtime > Change runtime type > Hardware accelerator***). Now we can install the `privacy-evaluator` package and import all needed modules."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "t_zNMqFHHUY4",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/privML/privacy-evaluator@team2sprint4\n",
            "  Cloning https://github.com/privML/privacy-evaluator (to revision team2sprint4) to /tmp/pip-req-build-5m188s68\n",
            "  Running command git clone -q https://github.com/privML/privacy-evaluator /tmp/pip-req-build-5m188s68\n",
            "  Running command git checkout -b team2sprint4 --track origin/team2sprint4\n",
            "  Switched to a new branch 'team2sprint4'\n",
            "  Branch 'team2sprint4' set up to track remote branch 'team2sprint4' from 'origin'.\n",
            "Requirement already satisfied (use --upgrade to upgrade): privacy-evaluator==0.1 from git+https://github.com/privML/privacy-evaluator@team2sprint4 in /home/ani/.local/lib/python3.8/site-packages\n",
            "Requirement already satisfied: adversarial-robustness-toolbox[pytorch,tensorflow]==1.6.2 in /home/ani/.local/lib/python3.8/site-packages (from privacy-evaluator==0.1) (1.6.2)\n",
            "Requirement already satisfied: matplotlib in /home/ani/.local/lib/python3.8/site-packages (from privacy-evaluator==0.1) (3.4.2)\n",
            "Requirement already satisfied: numpy in /home/ani/.local/lib/python3.8/site-packages (from privacy-evaluator==0.1) (1.20.2)\n",
            "Requirement already satisfied: pandas in /home/ani/.local/lib/python3.8/site-packages (from privacy-evaluator==0.1) (1.2.5)\n",
            "Requirement already satisfied: tensorflow in /home/ani/.local/lib/python3.8/site-packages (from privacy-evaluator==0.1) (2.5.0)\n",
            "Requirement already satisfied: torch in /home/ani/.local/lib/python3.8/site-packages (from privacy-evaluator==0.1) (1.9.0)\n",
            "Requirement already satisfied: torchvision in /home/ani/.local/lib/python3.8/site-packages (from privacy-evaluator==0.1) (0.10.0)\n",
            "Requirement already satisfied: scikit-learn<0.24.3,>=0.22.2 in /home/ani/.local/lib/python3.8/site-packages (from adversarial-robustness-toolbox[pytorch,tensorflow]==1.6.2->privacy-evaluator==0.1) (0.24.2)\n",
            "Requirement already satisfied: tqdm in /home/ani/.local/lib/python3.8/site-packages (from adversarial-robustness-toolbox[pytorch,tensorflow]==1.6.2->privacy-evaluator==0.1) (4.61.1)\n",
            "Requirement already satisfied: numba~=0.53.1 in /home/ani/.local/lib/python3.8/site-packages (from adversarial-robustness-toolbox[pytorch,tensorflow]==1.6.2->privacy-evaluator==0.1) (0.53.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /home/ani/.local/lib/python3.8/site-packages (from adversarial-robustness-toolbox[pytorch,tensorflow]==1.6.2->privacy-evaluator==0.1) (1.7.0)\n",
            "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from adversarial-robustness-toolbox[pytorch,tensorflow]==1.6.2->privacy-evaluator==0.1) (1.14.0)\n",
            "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from adversarial-robustness-toolbox[pytorch,tensorflow]==1.6.2->privacy-evaluator==0.1) (45.2.0)\n",
            "Requirement already satisfied: tensorflow-addons; extra == \"tensorflow\" in /home/ani/.local/lib/python3.8/site-packages (from adversarial-robustness-toolbox[pytorch,tensorflow]==1.6.2->privacy-evaluator==0.1) (0.13.0)\n",
            "Requirement already satisfied: h5py; extra == \"tensorflow\" in /home/ani/.local/lib/python3.8/site-packages (from adversarial-robustness-toolbox[pytorch,tensorflow]==1.6.2->privacy-evaluator==0.1) (3.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /home/ani/.local/lib/python3.8/site-packages (from matplotlib->privacy-evaluator==0.1) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /home/ani/.local/lib/python3.8/site-packages (from matplotlib->privacy-evaluator==0.1) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/ani/.local/lib/python3.8/site-packages (from matplotlib->privacy-evaluator==0.1) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ani/.local/lib/python3.8/site-packages (from matplotlib->privacy-evaluator==0.1) (1.3.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/lib/python3/dist-packages (from matplotlib->privacy-evaluator==0.1) (7.0.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /home/ani/.local/lib/python3.8/site-packages (from pandas->privacy-evaluator==0.1) (2021.1)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /home/ani/.local/lib/python3.8/site-packages (from tensorflow->privacy-evaluator==0.1) (1.1.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /home/ani/.local/lib/python3.8/site-packages (from tensorflow->privacy-evaluator==0.1) (0.2.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /home/ani/.local/lib/python3.8/site-packages (from tensorflow->privacy-evaluator==0.1) (1.6.3)\n",
            "Requirement already satisfied: wheel~=0.35 in /home/ani/.local/lib/python3.8/site-packages (from tensorflow->privacy-evaluator==0.1) (0.36.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /home/ani/.local/lib/python3.8/site-packages (from tensorflow->privacy-evaluator==0.1) (2.5.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /home/ani/.local/lib/python3.8/site-packages (from tensorflow->privacy-evaluator==0.1) (3.3.0)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /home/ani/.local/lib/python3.8/site-packages (from tensorflow->privacy-evaluator==0.1) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /home/ani/.local/lib/python3.8/site-packages (from tensorflow->privacy-evaluator==0.1) (3.7.4.3)\n",
            "Requirement already satisfied: gast==0.4.0 in /home/ani/.local/lib/python3.8/site-packages (from tensorflow->privacy-evaluator==0.1) (0.4.0)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /home/ani/.local/lib/python3.8/site-packages (from tensorflow->privacy-evaluator==0.1) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /home/ani/.local/lib/python3.8/site-packages (from tensorflow->privacy-evaluator==0.1) (3.17.3)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /home/ani/.local/lib/python3.8/site-packages (from tensorflow->privacy-evaluator==0.1) (1.1.2)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /home/ani/.local/lib/python3.8/site-packages (from tensorflow->privacy-evaluator==0.1) (1.12)\n",
            "Requirement already satisfied: absl-py~=0.10 in /home/ani/.local/lib/python3.8/site-packages (from tensorflow->privacy-evaluator==0.1) (0.13.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /home/ani/.local/lib/python3.8/site-packages (from tensorflow->privacy-evaluator==0.1) (1.12.1)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /home/ani/.local/lib/python3.8/site-packages (from tensorflow->privacy-evaluator==0.1) (1.34.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ani/.local/lib/python3.8/site-packages (from scikit-learn<0.24.3,>=0.22.2->adversarial-robustness-toolbox[pytorch,tensorflow]==1.6.2->privacy-evaluator==0.1) (2.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /home/ani/.local/lib/python3.8/site-packages (from scikit-learn<0.24.3,>=0.22.2->adversarial-robustness-toolbox[pytorch,tensorflow]==1.6.2->privacy-evaluator==0.1) (1.0.1)\n",
            "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in /home/ani/.local/lib/python3.8/site-packages (from numba~=0.53.1->adversarial-robustness-toolbox[pytorch,tensorflow]==1.6.2->privacy-evaluator==0.1) (0.36.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /home/ani/.local/lib/python3.8/site-packages (from tensorflow-addons; extra == \"tensorflow\"->adversarial-robustness-toolbox[pytorch,tensorflow]==1.6.2->privacy-evaluator==0.1) (2.12.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3/dist-packages (from tensorboard~=2.5->tensorflow->privacy-evaluator==0.1) (2.22.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /home/ani/.local/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow->privacy-evaluator==0.1) (3.3.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/ani/.local/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow->privacy-evaluator==0.1) (0.4.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/ani/.local/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow->privacy-evaluator==0.1) (1.8.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/ani/.local/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow->privacy-evaluator==0.1) (1.32.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/ani/.local/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow->privacy-evaluator==0.1) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /home/ani/.local/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow->privacy-evaluator==0.1) (2.0.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ani/.local/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow->privacy-evaluator==0.1) (1.3.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/ani/.local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->privacy-evaluator==0.1) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ani/.local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->privacy-evaluator==0.1) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /home/ani/.local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->privacy-evaluator==0.1) (4.7.2)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow->privacy-evaluator==0.1) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ani/.local/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->privacy-evaluator==0.1) (0.4.8)\n",
            "Building wheels for collected packages: privacy-evaluator\n",
            "  Building wheel for privacy-evaluator (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for privacy-evaluator: filename=privacy_evaluator-0.1-py3-none-any.whl size=28617451 sha256=9d10862e40241f03076e08bdf69e71e5b9496123855727ab62e1363fecea2731\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-_gxjynn2/wheels/17/a8/12/f05e8cd0aa70c8b9696e12d21946242d012c4ba1d6b54d9d6c\n",
            "Successfully built privacy-evaluator\n"
          ]
        }
      ],
      "source": [
        "!pip3 install git+https://github.com/privML/privacy-evaluator@team2sprint4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "10607993"
      },
      "outputs": [],
      "source": [
        "from privacy_evaluator.attacks.property_inference_attack import PropertyInferenceAttack\n",
        "from privacy_evaluator.classifiers.classifier import Classifier\n",
        "from privacy_evaluator.utils.data_utils import (\n",
        "    dataset_downloader,\n",
        "    new_dataset_from_size_dict,\n",
        ")\n",
        "from privacy_evaluator.utils.trainer import trainer\n",
        "from privacy_evaluator.models.torch.cnn import ConvNet\n",
        "\n",
        "import collections\n",
        "from matplotlib import pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hedtyyE_GZ7Z"
      },
      "source": [
        "\n",
        "# Conduct Property Inference Attack\n",
        "Now we can start with conducting the Property Inference Attack.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Preparation of the dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1 Download the dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will work with the MNIST dataset.\\\n",
        "MNIST is a dataset of black-and-white handwritten digits from 10 classes (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), consisting of 60000 training- and 10000 test-images.\n",
        "\n",
        "First, we download the MNIST dataset.\\\n",
        "The size of each image is $28\\times 28 \\times 1$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jt71upsQGZ7a",
        "outputId": "df64070d-e7c1-48cd-db94-e6632f5d0ce0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input shape of images: (28, 28, 1)\n"
          ]
        }
      ],
      "source": [
        "train_dataset, test_dataset = dataset_downloader(\"MNIST\")\n",
        "input_shape = test_dataset[0][0].shape\n",
        "print(f\"Input shape of images: {input_shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can see some sample images of the MNIST dataset printed below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 576x576 with 3 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Print images\n",
        "images = test_dataset[0][:3]\n",
        "_, axs = plt.subplots(1, 3, figsize=(8, 8))\n",
        "axs = axs.flatten()\n",
        "for image, ax in zip(images, axs):\n",
        "    ax.imshow(image, cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaZ15iLZGZ7c"
      },
      "source": [
        "### 1.2 Adjustment of dataset to binary attack\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As of now, we can only perform binary attacks.\\\n",
        "A binary attack is a attack, where the target model is only classifying into 2 different classes.\\\n",
        "This means that the dataset the target model is trained on only contain two different classes. For our example we therefore use classes 0 and 1 from MNIST, which represent the digits 0 and 1.\n",
        "\n",
        "We specify a distribution of these two classes (`NUM_ELEMENTS_PER_CLASSES`) and adjust the MNIST dataset accordingly. \\\n",
        "On this adjusted dataset we will train our target model and later the attacks goal is to predict this distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "WmHrXo7QGZ7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Amount of images per class: {0: 1000, 1: 500}\n",
            "Amount of images in total: (1500,)\n",
            "Size of each image: (28, 28, 1)\n"
          ]
        }
      ],
      "source": [
        "NUM_ELEMENTS_PER_CLASSES = {0: 1000, 1: 500}\n",
        "train_set = new_dataset_from_size_dict(train_dataset, NUM_ELEMENTS_PER_CLASSES)\n",
        "print(f\"Amount of images per class: {NUM_ELEMENTS_PER_CLASSES}\")\n",
        "print(f\"Amount of images in total: {train_set[1].shape}\")\n",
        "print(f\"Size of each image: {train_set[0][0].shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2IFaCSoGZ7f"
      },
      "source": [
        "## 2. Load and train target model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now load our target model.\\\n",
        "We use a convolutional neural network (CNN) and train it on the dataset created in the step before. \\\n",
        "We then convert it to an ART classifier to make it compatible with the [Adversial Robustness Toolbox](https://github.com/Trusted-AI/adversarial-robustness-toolbox). This step is not important to understand for the actual attack but might be interesting to know for you if know the ART.\n",
        "\n",
        "Our target model is now all set for the actual attack on it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "Rr4BA37yGZ7i"
      },
      "outputs": [],
      "source": [
        "num_classes = len(NUM_ELEMENTS_PER_CLASSES)\n",
        "model = ConvNet(num_classes, input_shape, num_channels=(input_shape[-1], 16, 32, 64))\n",
        "trainer(train_set, NUM_ELEMENTS_PER_CLASSES, model, num_epochs=8)\n",
        "\n",
        "# Convert to ART classifier\n",
        "\n",
        "target_model = Classifier._to_art_classifier(model, \"sparse_categorical_crossentropy\", num_classes, input_shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gG36p_-IGZ7k"
      },
      "source": [
        "## 3. Perform attack\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1 Overview over whole attack"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "One property inference attack consists of several property inference subattacks for different distributions of the training data. One subattack is running for one ratio (e.g. 66% class 0, 34% class 1) and predicts whether it's more likely that the distribution of the training data of the target model was according to this special ratio or a balanced distribution (50% class 0, 50% class 1). \\\n",
        "We specify the ratios in `ratios_for_attack`. We only specify one ratio for class 0 in the list, the other one for class 1 is automatically computed in the attack (1 - ratio for class 0). \\\n",
        "The whole attack then checks, which distribution of the subattacks has the highest probability.\n",
        "\n",
        "![Property_Inference_Attack_overview](https://i.imgur.com/yHPc8bO.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Overview over a subattack\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In every subattack we create a number of shadow classifiers of the same architecture as the provided target model.\n",
        "\n",
        "![shadow_classifiers](https://i.imgur.com/vffpROO.jpg)\n",
        "\n",
        "Half of the shadow classifiers is trained on an unbalanced data set of the given ratio (e.g. 70% class 0, 30% class 1) - our property -, the other half is trained on a balanced data sets (50% class 0, 50% class 1) - our negation of property.\n",
        "\n",
        "![shadow_training_sets](https://i.imgur.com/ryUDdbK.jpg)\n",
        "\n",
        "Once created and trained, the features of the shadow classifiers are extracted. Generally speaking, the extracted features are nothing more than on what specifics of the image the model determined its prediction. \\\n",
        "The extracted features are then the training data for the meta classifier. This means that the meta classifier is trained to distinguish between the property and the negation of property (unbalanced with specific ratio vs. balanced).\n",
        "\n",
        "![meta_classifier](https://i.imgur.com/mhpkRm2.jpg)\n",
        "\n",
        "Hence, the meta classifier gets as an input the feature extraction of the target model. \n",
        "\n",
        "If the data set used for the target model does indeed follow the property (unbalanced with specific ratio), the extracted features of the target model will show simularities to the feature extractions of the shadow classifiers trained on data sets that follow the property. Thus, the meta classifier will predict in this case that the likelihood of the target model to have the given property is higher than it having the negation of the property (similar procedure in the opposite case that the data set of the target model follows the negation of the property). \n",
        "\n",
        "To conclude, the meta classifier is the model which finally predicts the likelihood of the target model to have a given property (i.e. the ratio).\n",
        "\n",
        "![prediction](https://i.imgur.com/Skf8j7S.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3 Perform actual attack"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To now perform the attack, we first define how many shadow classifiers we want to create (`number_of_shadow_classifiers`). In `size_set` we define the size of the training data set for each shadow classifier. \n",
        "\n",
        "As you can see, in our example attack we set `number_of_shadow_classifiers` to 2, and `size_set` to 6. This means that two shadow classifiers will be trained (remember: in a subattack half of the shadow classifiers follow the property, half follow the negation of property so in our case 1 shadow classifier is trained on an unbalanced data set, 1 shadow classifier is trained on a balanced data set). Each shadow classifier is trained on a data set with 6 images.\n",
        "\n",
        "For both parameters we chose really small numbers due to runtime issues, but for a real attack <1000 shadow classifiers are not recommended and also the size set should be increased according to the size of the dataset you're sampling from. In the case of MNIST set sizes between 500 and 1500 are reasonable.\n",
        "\n",
        "We also define which classes we want to use for our binary attack (`classes`) and the unbalanced ratios for each subattack (`ratios_for_attack`). \n",
        "\n",
        "In our case, two subattacks will be performed, one with 66% images from class 0 and 34% images from class 1, the other with 5% from class 0, 95% from class 1.\n",
        "\n",
        "We again chose very less ratios due to runtime issues. For a real attack, it is again recommended to have many more subattacks for more ratios."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "qNThcpLfGZ7k"
      },
      "outputs": [],
      "source": [
        "# Number of shadow classifiers (increase for better accuracy of the meta classifier, decrease when not enough computing power is available.)\n",
        "number_of_shadow_classifiers = 2 #needs to be even\n",
        "\n",
        "# Size of data set to train the shadow classifiers\n",
        "size_set = 6\n",
        "\n",
        "#Ratios to perform the attack for (the real ratios of our example target model is 0.66: {0: 1000, 1: 500}: 66% of data points are from class 0, 33% from class 1.)\n",
        "ratios_for_attack = [0.66,0.05]\n",
        "\n",
        "#Classes that the attack should be performed on\n",
        "classes = [0,1] #needs to be two values (binary attack)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We then perform the attack on the target model (`target_model`) with our MNIST dataset (`train_set`) and with the values that we defined just now. Further, the verbose variable is set to 1 which means that when you run the attack you will get some printed statements of what the attack is doing right now. \\\n",
        "The attack consists of all the steps explained in \"3.1 Overview over whole attack\" and \"3.2 Ovierview over a subattack\".\n",
        "\n",
        "We save the output of the attack in the variable `output`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3aihZM-GZ7l",
        "outputId": "99216e1b-7da5-427b-f20e-1531275ce0e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initiating Property Inference Attack ... \n",
            "Extracting features from target model ... \n",
            "(97634,)  --- features extracted from the target model.\n",
            "Creating set of 1 balanced shadow classifiers ... \n",
            "Creating shadow training sets\n",
            "Training shadow classifiers\n",
            "Performing PIA for various ratios ... \n",
            "  0%|          | 0/2 [00:00<?, ?it/s]Creating shadow training sets\n",
            "Training shadow classifiers\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 7s 7s/step - loss: 2.2833 - accuracy: 0.0000e+00\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 503ms/step - loss: 0.2296 - accuracy: 1.0000\n",
            " 50%|█████     | 1/2 [00:13<00:13, 13.28s/it]Creating shadow training sets\n",
            "Training shadow classifiers\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 6s 6s/step - loss: 0.5541 - accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 1s 533ms/step - loss: 1.6616 - accuracy: 0.0000e+00\n",
            "100%|██████████| 2/2 [00:21<00:00, 10.54s/it]\n"
          ]
        }
      ],
      "source": [
        "attack = PropertyInferenceAttack(target_model, train_set, verbose=1, size_set=size_set, \\\n",
        "    ratios_for_attack=ratios_for_attack, classes=classes,amount_sets=number_of_shadow_classifiers)\n",
        "output = attack.attack()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Output of attack"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1 Whole output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The output consists of two elements. \\\n",
        " One is a string with a message where the actual prediction is printed. \\\n",
        " The other one is a dictionary where for every ratio specified before in `ratios_for attack` we get the likelihood that the training set was this ratio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('The most probable property is class 0: 0.95, class 1: 0.05 with a probability of 0.49737825989723206.',\n",
              " {'class 0: 0.95, class 1: 0.05': 0.49737826,\n",
              "  'class 0: 0.34, class 1: 0.66': 0.48793313})"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 Understanding the output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The human readable output message is the string, it gives us the actual prediction. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The most probable property is class 0: 0.95, class 1: 0.05 with a probability of 0.49737825989723206.'"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vokop1MmGZ7l",
        "outputId": "36a8d0be-4447-40c2-bb1e-6e27b450e84f"
      },
      "source": [
        "E.g. the output is _'The most probable property is class 0: 0.34, class 1: 0.66 with a probability of 0.5118420720100403.'_ \n",
        " \n",
        "The part of the output _'class 0: 0.34, class 1: 0.66 with a probability of 0.5118420720100403.'_ means that the subattack which had as the unbalanced ratio (property) for the data set \n",
        " - 34 % of the images in the data set are from class 0\n",
        " - 66% % of the images in the data set are from class 1 \n",
        " \n",
        "had a ~51% chance of this being the distribution of the data set the target model was trained rather than a balanced distribution. \\\n",
        "In other words: The chance that the distribution of the target model's data set was balanced instead of 34%/66% is ~49%.\n",
        "\n",
        "Now looking at the whole string _'The most probable property is class 0: 0.34, class 1: 0.66 with a probability of 0.5118420720100403.'_: This means that the prediction is the most likely property. In other words, from all the unbalanced ratios (class distributions) that were tested as properties in the subattacks, this property has the highest probability. \\\n",
        "Hence, from all unbalanced class distributions tested, this is most likely the class distribiution of the data set the target model was trained on. \n",
        "\n",
        "It is important to mention that so far, the attack only outputs the most likely distribution from all unbalanced distributions that were tested. The negation of the property (balanced distribution) is neglected so far as more research is needed to answer this question.\\\n",
        "This means that the output right now does not say whether the data set the target model was trained on is balanced or unbalanced but rather which of the tested unbalanced ratios is the most likely.\\\n",
        "To avoid this shortcoming of the attack to have influence on our example, we therefore performed the attack on a target model that was trained on an unbalanced data set (66%, 34%).\n",
        "\n",
        "![output](https://i.imgur.com/mZeGe6N.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The more detailed output you could use for visualization or further analysis is the dictionary. \\\n",
        "This output shows the propability for all ratios, not only the most likely.\\\n",
        "It is simular constructed to above in detailed described propability for the most likely ratio. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'class 0: 0.95, class 1: 0.05': 0.49737826,\n",
              " 'class 0: 0.34, class 1: 0.66': 0.48793313}"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.3 Improve output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 4.3.1 Probabilities close to 0.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If all the probabilities are close to 0.5 and none is standing out significantly from all the others you could try using more shadow classifiers (= make the training set for the meta classifier larger).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 4.3.2 Output overall"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As mentioned before, we used very small values to make the notebook quick and easy to use. \n",
        "\n",
        "To perform a stronger attack generally speaking, we would advise to use more shadow classifiers (>1000), bigger shadow training sets (for MNIST > 500) and more subattacks (= more ratios). "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "property_inference_attack.py.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "fd69f43f58546b570e94fd7eba7b65e6bcc7a5bbc4eab0408017d18902915d69"
    },
    "kernelspec": {
      "display_name": "Python 3.7.10 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "metadata": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}