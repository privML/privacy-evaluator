{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Membership Privacy Risk Score Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/privML/privacy-evaluator/blob/feat/116-testable-notebooks/notebooks/membership_privacy_risk_score.ipynb\"><img src=\"https://raw.githubusercontent.com/privML/privacy-evaluator/feat/116-testable-notebooks/notebooks/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/privML/privacy-evaluator/blob/feat/116-testable-notebooks/notebooks/membership_privacy_risk_score.ipynb\"><img src=\"https://raw.githubusercontent.com/privML/privacy-evaluator/feat/116-testable-notebooks/notebooks/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "In this notebook we'll use two simple image classification models pre-trained on the CIFAR10 dataset. The architecture of both models are based on https://www.scitepress.org/Papers/2018/67520/67520.pdf, one being implemented in PyTorch and the other in TensorFlow. The models will be used to compute each sample's probability of being in the training set, denoted as membership privacy risk score or short privacy risk score (cf. https://arxiv.org/abs/2003.10595). As dataset we will use the original CIFAR10 dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "First, we should set this notebook's runtime to use a GPU (e.g. if Colab is used go to ***Runtime > Change runtime type > Hardware accelerator***). Now we can install the `privacy-evaluator` package and import all needed modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install git+https://github.com/privML/privacy-evaluator@feat/116-testable-notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import privacy_evaluator.models.torch.dcti.dcti as torch_dcti\n",
    "import privacy_evaluator.models.tf.dcti.dcti as tf_dcti \n",
    "from privacy_evaluator.datasets.cifar10 import CIFAR10\n",
    "from privacy_evaluator.classifiers.classifier import Classifier\n",
    "\n",
    "from privacy_evaluator.metrics.privacy_risk_score import * \n",
    "from privacy_evaluator.output.user_output import UserOutput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Membership Privacy Risk Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch\n",
    "\n",
    "We start the evaluation with the PyTorch model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load CIFAR10 Dataset\n",
    "\n",
    "Before we can start computing the membership privacy risk scores, we need to load the dataset. The CIFAR10 dataset needs to be preprocesses in a specific manner to work for the PyTorch model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR10 dataset as numpy array\n",
    "x_train, y_train, x_test, y_test = CIFAR10.numpy(model_type='torch')\n",
    "\n",
    "# Number of classes of CIFAR10 dataset\n",
    "nb_classes=CIFAR10.N_CLASSES, \n",
    "\n",
    "# Input shape of CIFAR10 dataset\n",
    "input_shape=CIFAR10.INPUT_SHAPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare target model\n",
    "\n",
    "Now we can set the loss function (in our case it is the `torch.nn.CrossEntropyLoss`) of the model and initialize the model as a generic `Classifier` with the corresponding values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function of the Pytrorch model\n",
    "torch_loss = torch.nn.CrossEntropyLoss(reduction=\"none\")\n",
    "\n",
    "# Initalize PyTorch model as a Classifier\n",
    "torch_target_model = Classifier(\n",
    "    torch_dcti.load_dcti(), \n",
    "    loss=torch_loss, \n",
    "    nb_classes=nb_classes, \n",
    "    input_shape=input_shape\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute privacy risk score\n",
    "We can then compute the privacy risk scores. As a result, we get scores for the train and test set separately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute membership privacy risk score for the PyTorch model\n",
    "(\n",
    "    train_privacy_risk_score, \n",
    "    test_privacy_risk_score\n",
    ") = compute_privacy_risk_score(\n",
    "    torch_target_model, \n",
    "    x_train[:100], \n",
    "    y_train[:100], \n",
    "    x_test[:100], \n",
    "    y_test[:100]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualise the result\n",
    "As the last step, we then visualize the results as a histogram. The histogram depicts the k-top most vulnerable points of the dataset per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create user output and plot histogram for train dataset\n",
    "user_output = UserOutput(\n",
    "    np.argmax(y_train[:100], axis=1),\n",
    "    train_privacy_risk_score, \n",
    "    range(10)\n",
    ")\n",
    "\n",
    "labels, count = user_output.histogram_top_k(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create user output and plot histogram for test dataset\n",
    "user_output = UserOutput(\n",
    "    np.argmax(y_test[:100], axis=1),\n",
    "    test_privacy_risk_score, \n",
    "    range(10)\n",
    ")\n",
    "\n",
    "labels, count = user_output.histogram_top_k(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow\n",
    "\n",
    "Now we do the same with the TensorFlow model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load CIFAR10 Dataset\n",
    "\n",
    "Again, we load the correct dataset for the TensorFLow model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR10 dataset as numpy array\n",
    "x_train, y_train, x_test, y_test = CIFAR10.numpy(model_type='tf')\n",
    "\n",
    "# Number of classes of CIFAR10 dataset\n",
    "nb_classes=CIFAR10.N_CLASSES, \n",
    "\n",
    "# Input shape of CIFAR10 dataset\n",
    "input_shape=CIFAR10.INPUT_SHAPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare target model\n",
    "\n",
    "Then we initialize the target model. This time we use the `tf.keras.losses.CategoricalCrossentropy` as loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function of the TensorFlow target model\n",
    "tf_loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "# Initalize TensorFlow target model\n",
    "tf_target_model = Classifier(\n",
    "    tf_dcti.load_dcti(), \n",
    "    loss=tf_loss, \n",
    "    nb_classes=nb_classes, \n",
    "    input_shape=input_shape\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute privacy risk score\n",
    "Next, we can then compute the privacy risk scores. As a result, we get scores for the train and test set separately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute privacy risk score for the TensorFlow target model\n",
    "(\n",
    "    train_privacy_risk_score, \n",
    "    test_privacy_risk_score\n",
    ") = compute_privacy_risk_score(\n",
    "    tf_target_model, \n",
    "    x_train[:100], \n",
    "    y_train[:100], \n",
    "    x_test[:100], \n",
    "    y_test[:100]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualise the result\n",
    "Now, we can again visualize the results as a histogram. The histogram depicts the k-top most vulnerable points of the dataset per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create user output and plot histogram for train dataset\n",
    "user_output = UserOutput(\n",
    "    np.argmax(y_train[:100], axis=1), \n",
    "    train_privacy_risk_score, \n",
    "    range(10)\n",
    ")\n",
    "\n",
    "labels, count = user_output.histogram_top_k(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create user output and plot histogram for test dataset\n",
    "user_output = UserOutput(\n",
    "    np.argmax(y_test[:100], axis=1), \n",
    "    test_privacy_risk_score, \n",
    "    range(10)\n",
    ")\n",
    "\n",
    "labels, count = user_output.histogram_top_k(50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "privacy-evaluator-venv",
   "language": "python",
   "name": "privacy-evaluator-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
