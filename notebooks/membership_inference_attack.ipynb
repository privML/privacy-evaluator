{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Membership Inference Attack Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/privML/privacy-evaluator/blob/feat/116-testable-notebooks/notebooks/membership_inference_attack.ipynb\"><img src=\"https://raw.githubusercontent.com/privML/privacy-evaluator/feat/116-testable-notebooks/notebooks/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/privML/privacy-evaluator/blob/feat/116-testable-notebooks/notebooks/membership_inference_attack.ipynb\"><img src=\"https://raw.githubusercontent.com/privML/privacy-evaluator/feat/116-testable-notebooks/notebooks/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In this notebook, we want to show you how to use the `privacy-evaluator` tool to perform Membership Inference Attacks (short MIA) on either a PyTorch or Tensorflow model. We will conduct three different Membership Inference Attack Methods: a Black Box Attack, a Black Box Rule-Based Attack and a Label Only Decision Boundary Attack."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, you should set the notebook's runtime to use a GPU (e.g. if Colab is used go to ***Runtime > Change runtime type > Hardware accelerator***). Now we can install the `privacy-evaluator` package and import all needed modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install git+https://github.com/privML/privacy-evaluator@feat/116-testable-notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7ab468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow.python.ops.numpy_ops.np_config as np_config\n",
    "np_config.enable_numpy_behavior()\n",
    "\n",
    "import privacy_evaluator.models.torch.dcti.dcti as torch_dcti\n",
    "import privacy_evaluator.models.tf.dcti.dcti as tf_dcti \n",
    "\n",
    "from privacy_evaluator.datasets.tf.cifar10 import TFCIFAR10\n",
    "from privacy_evaluator.datasets.torch.cifar10 import TorchCIFAR10\n",
    "\n",
    "from privacy_evaluator.classifiers.classifier import Classifier\n",
    "\n",
    "from privacy_evaluator.attacks.membership_inference.black_box import MembershipInferenceBlackBoxAttack\n",
    "from privacy_evaluator.attacks.membership_inference.black_box_rule_based import MembershipInferenceBlackBoxRuleBasedAttack\n",
    "from privacy_evaluator.attacks.membership_inference.label_only_decision_boundary import MembershipInferenceLabelOnlyDecisionBoundaryAttack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conduct Membership Inference Attacks\n",
    "\n",
    "Now we can start with conducting the Membership Inference Attacks. Therefore, we prepared two similar paths: one for the PyTorch model and one for the TensorFlow model. For both paths, we use simple neural networks trained on the CIFAR-10 dataset and implement a Lightweight Deep Convolutional Neural Network architecture (For more details, please read the following paper: https://www.scitepress.org/Papers/2018/67520/67520.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2da0876",
   "metadata": {},
   "source": [
    "### PyTorch\n",
    "\n",
    "We start the evaluation with the PyTorch model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load CIFAR10 Dataset\n",
    "\n",
    "Before we can start to conduct the membership inference attacks, we need to load the dataset. The CIFAR10 dataset needs to be preprocessed in a specific manner to work for the PyTorch model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcae11d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR10 dataset as numpy array\n",
    "x_train, y_train, x_test, y_test = TorchCIFAR10.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare target model\n",
    "\n",
    "Now, we need to initialize our pre-trained Lightweight Deep Convolutional Neural Network (short DCTI) as a generic `Classifier`. Therefore we need to specify the loss function used to train the model (in our case the `torch.nn.CrossEntropyLoss`), the number of classes and the input shape of our CIFAR-10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initalize PyTorch model as a Classifier\n",
    "target_model = Classifier(\n",
    "    torch_dcti.load_dcti(), # PyTorch DCTI \n",
    "    loss=torch.nn.CrossEntropyLoss(reduction=\"none\"), # Loss function of the PyTorch model\n",
    "    nb_classes=TorchCIFAR10.N_CLASSES, # Number of classes of the CIFAR10 dataset\n",
    "    input_shape=TorchCIFAR10.INPUT_SHAPE # Input shape of the CIFAR10 dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7761c0c",
   "metadata": {},
   "source": [
    "#### Perform Membership Inference Black Box Attack\n",
    "\n",
    "First, we want to attack our target model with the Membership Inference  Black Box Attack. Thus, we initialize the attack with the target model and a dataset used to fit the attack model. The dataset consists of two different sets. The first contains data (`x_train`) and its corresponding labels (`y_train`) which were used to train the target model. The second contains data (`x_test`) and its corresponding labels (`y_test`) which were not part of the training process of the target model. After the initialization, we first need to fit the attack model before we can attack the target model. To attack certain data points, we simply input them into the `attack()` method. The result of the attack is an array holding the inferred membership status, 1 indicates a member and 0 indicates non-member."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9e4799",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack = MembershipInferenceBlackBoxAttack(\n",
    "    target_model, \n",
    "    x_train[:100], \n",
    "    y_train[:100], \n",
    "    x_test[:100], \n",
    "    y_test[:100]\n",
    ")\n",
    "\n",
    "attack.fit()\n",
    "attack.attack(x_train[:100], y_train[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5770d67d",
   "metadata": {},
   "source": [
    "#### Get machine-readable attack statistics\n",
    "\n",
    "Besides the inferred membership status, we can create more general statistics. To do so, we generate an attack output by providing again the data points which should be attacked and the correct inferred membership labels (in this case all attacked data points are part of the training dataset and thus for all of them a membership should be predicted by the attack model). As result, we get the accuracy, the train-to-test accuracy gap and the train-to-test ratio for the target model and the accuracy for the attack model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaa9ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = attack.attack_output(\n",
    "    x_train[:100], \n",
    "    y_train[:100], \n",
    "    np.ones((100,))\n",
    ")\n",
    "\n",
    "output.to_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a432f6",
   "metadata": {},
   "source": [
    "#### Perform Membership Inference Black Box Rule Based Attack\n",
    "\n",
    "Next, we want to perform a Membership Inference Black Box Rule-Based Attack. In this case, we do not need to fit the attack because this approach is fully rule-based and depends only on the attacked data points and the target model. That means, every time the target model classifies a data point correctly, the attack model identifies the datapoint as a member and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c9fc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack = MembershipInferenceBlackBoxRuleBasedAttack(\n",
    "    target_model, \n",
    "    x_train, \n",
    "    y_train, \n",
    "    x_test, \n",
    "    y_test\n",
    ")\n",
    "\n",
    "attack.attack(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ecb6b3",
   "metadata": {},
   "source": [
    "#### Get pythonic attack statistics\n",
    "\n",
    "Again, we want to get a better overview of the attack results. This time we want to receive the result in a more pythonic manner and we are only interested in the attack model's accuracy. Therefore, we filter the output and convert it into a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274272d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = attack.attack_output(\n",
    "    x_train, \n",
    "    y_train,\n",
    "    np.ones((len(y_train),))\n",
    ")\n",
    "\n",
    "output.to_dict(filter=[\"attack_model_accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee10af5d",
   "metadata": {},
   "source": [
    "#### Perform Membership Inference Label Only Decision Boundary Attack\n",
    "\n",
    "Last but not least, we want to perform a Label Only Decision Boundary Attack. We again need to train the attack model first. This attack is really time expensive, thus we only fit the attack on a very small set which is not realistic and should not be repeated in production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73278928",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack = MembershipInferenceLabelOnlyDecisionBoundaryAttack(\n",
    "    target_model, \n",
    "    x_train[:1], \n",
    "    y_train[:1], \n",
    "    x_test[:1], \n",
    "    y_test[:1]\n",
    ")\n",
    "\n",
    "attack.fit(max_iter=1, max_eval=1, init_eval=1)\n",
    "attack.attack(x_train[:1], y_train[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0b5639",
   "metadata": {},
   "source": [
    "#### Get human-readable attack statistics\n",
    "\n",
    "For this attack we want a human-readable output, thus we convert it to a sting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3551f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = attack.attack_output(\n",
    "    x_train[:1], \n",
    "    y_train[:1], \n",
    "    np.ones((1,))\n",
    ")\n",
    "\n",
    "str(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2da0876",
   "metadata": {},
   "source": [
    "### TensorFlow\n",
    "\n",
    "Now we do the same with the TensorFlow model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load CIFAR10 Dataset\n",
    "\n",
    "Again, before we can start to conduct the membership inference attacks, we need to load the dataset. The CIFAR10 dataset needs to be preprocessed in a specific manner to work for the TensorFlow model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcae11d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR10 dataset as numpy array\n",
    "x_train, y_train, x_test, y_test = TFCIFAR10.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare target model\n",
    "\n",
    "Now, we need to initialize our pre-trained Lightweight Deep Convolutional Neural Network (short DCTI) as a generic `Classifier`. Therefore we need to specify the loss function used to train the model (in our case the `tf.keras.losses.CategoricalCrossentropy`), the number of classes and the input shape of our CIFAR-10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initalize TensorFlow target model\n",
    "target_model = Classifier(\n",
    "    tf_dcti.load_dcti(), # TensorFlow DCTI\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(), # Loss function of the TensorFlow target model\n",
    "    nb_classes=TFCIFAR10.N_CLASSES, # Number of classes of the CIFAR10 dataset\n",
    "    input_shape=TFCIFAR10.INPUT_SHAPE # Input shape of the CIFAR10 dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7761c0c",
   "metadata": {},
   "source": [
    "#### Perform Membership Inference Black Box Attack\n",
    "\n",
    "First, we want to attack our target model with the Membership Inference  Black Box Attack. Thus, we initialize the attack with the target model and a dataset used to fit the attack model. The dataset consists of two different sets. The first contains data (`x_train`) and its corresponding labels (`y_train`) which were used to train the target model. The second contains data (`x_test`) and its corresponding labels (`y_test`) which were not part of the training process of the target model. After the initialization, we first need to fit the attack model before we can attack the target model. To attack certain data points, we simply input them into the `attack()` method. The result of the attack is an array holding the inferred membership status, 1 indicates a member and 0 indicates non-member."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9e4799",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack = MembershipInferenceBlackBoxAttack(\n",
    "    target_model, \n",
    "    x_train[:100], \n",
    "    y_train[:100], \n",
    "    x_test[:100], \n",
    "    y_test[:100]\n",
    ")\n",
    "\n",
    "attack.fit()\n",
    "attack.attack(x_train[:100], y_train[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5770d67d",
   "metadata": {},
   "source": [
    "#### Get machine-readable attack statistics\n",
    "\n",
    "Besides the inferred membership status, we can create more general statistics. To do so, we generate an attack output by providing again the data points which should be attacked and the correct inferred membership labels (in this case all attacked data points are part of the training dataset and thus for all of them a membership should be predicted by the attack model). As result, we get the accuracy, the train-to-test accuracy gap and the train-to-test ratio for the target model and the accuracy for the attack model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaa9ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = attack.attack_output(\n",
    "    x_train[:100], \n",
    "    y_train[:100], \n",
    "    np.ones((100,))\n",
    ")\n",
    "\n",
    "output.to_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a432f6",
   "metadata": {},
   "source": [
    "#### Perform Membership Inference Black Box Rule Based Attack\n",
    "\n",
    "Next, we want to perform a Membership Inference Black Box Rule-Based Attack. In this case, we do not need to fit the attack because this approach is fully rule-based and depends only on the attacked data points and the target model. That means, every time the target model classifies a data point correctly, the attack model identifies the datapoint as a member and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c9fc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack = MembershipInferenceBlackBoxRuleBasedAttack(\n",
    "    target_model, \n",
    "    x_train, \n",
    "    y_train, \n",
    "    x_test, \n",
    "    y_test\n",
    ")\n",
    "\n",
    "attack.attack(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ecb6b3",
   "metadata": {},
   "source": [
    "#### Get pythonic attack statistics\n",
    "\n",
    "Again, we want to get a better overview of the attack results. This time we want to receive the result in a more pythonic manner and we are only interested in the attack model's accuracy. Therefore, we filter the output and convert it into a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274272d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = attack.attack_output(\n",
    "    x_train, \n",
    "    y_train, \n",
    "    np.ones((len(y_train),))\n",
    ")\n",
    "\n",
    "output.to_dict(filter=[\"attack_model_accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee10af5d",
   "metadata": {},
   "source": [
    "#### Perform Membership Inference Label Only Decision Boundary Attack\n",
    "\n",
    "Last but not least, we want to perform a Label Only Decision Boundary Attack. We again need to train the attack model first. This attack is really time expensive, thus we only fit the attack on a very small set which is not realistic and should not be repeated in production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73278928",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack = MembershipInferenceLabelOnlyDecisionBoundaryAttack(\n",
    "    target_model, \n",
    "    x_train[:1], \n",
    "    y_train[:1], \n",
    "    x_test[:1], \n",
    "    y_test[:1]\n",
    ")\n",
    "\n",
    "attack.fit(max_iter=1, max_eval=1, init_eval=1)\n",
    "attack.attack(x_train[:1], y_train[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0b5639",
   "metadata": {},
   "source": [
    "#### Get human-readable attack statistics\n",
    "\n",
    "For this attack we want a human-readable output, thus we convert it to a sting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3551f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = attack.attack_output(\n",
    "    x_train[:1], \n",
    "    y_train[:1], \n",
    "    np.ones((1,))\n",
    ")\n",
    "\n",
    "str(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "privacy-evaluator-venv",
   "language": "python",
   "name": "privacy-evaluator-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
