{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.5 64-bit"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "interpreter": {
      "hash": "4e1d9a8909477db77738c33245c29c7265277ef753467dede8cf3f814cde494e"
    },
    "colab": {
      "name": "property_inference_attack.py.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvfxnZUWGZ7R"
      },
      "source": [
        "## Demo for Property Inference Attack (PIA)"
      ],
      "id": "DvfxnZUWGZ7R"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPDjZtZbIZaf"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/privML/privacy-evaluator/blob/feat/138-notebook/notebooks/property_inference_attack.py.ipynb) [![Open in Github](https://raw.githubusercontent.com/privML/privacy-evaluator/main/notebooks/images/GitHub-Mark-32px.png)](https://github.com/privML/privacy-evaluator/blob/feat/138-notebook/notebooks/property_inference_attack.py.ipynb)\n",
        "\n",
        "\n"
      ],
      "id": "MPDjZtZbIZaf"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_zNMqFHHUY4"
      },
      "source": [
        "!pip3 install git+https://github.com/privML/privacy-evaluator@feat/138-notebook"
      ],
      "id": "t_zNMqFHHUY4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10607993"
      },
      "source": [
        "from privacy_evaluator.attacks.property_inference_attack import PropertyInferenceAttack\n",
        "from privacy_evaluator.classifiers.classifier import Classifier\n",
        "from privacy_evaluator.utils.data_utils import (\n",
        "    dataset_downloader,\n",
        "    new_dataset_from_size_dict,\n",
        ")\n",
        "from privacy_evaluator.utils.trainer import trainer\n",
        "from privacy_evaluator.models.torch.cnn import ConvNet\n",
        "\n",
        "import collections\n",
        "from matplotlib import pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "id": "10607993",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hedtyyE_GZ7Z"
      },
      "source": [
        "\n",
        "# Property Inference Attack on CIFAR10 Dataset\n",
        "\n",
        "## 1. Overview of the Dataset\n",
        "\n",
        "CIFAR10 is a dataset of colorful (RGB) images from 10 classes (airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck), consisting of 50000 training- and 10000 test- examples.\n",
        "\n",
        "The size of each image is $32\\times 32 \\times 3$:\n"
      ],
      "id": "hedtyyE_GZ7Z"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jt71upsQGZ7a",
        "outputId": "df64070d-e7c1-48cd-db94-e6632f5d0ce0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_dataset, test_dataset = dataset_downloader(\"CIFAR10\")\n",
        "input_shape = test_dataset[0][0].shape\n",
        "print(input_shape)"
      ],
      "id": "Jt71upsQGZ7a",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "(32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaZ15iLZGZ7c"
      },
      "source": [
        "As of now we can only perform binary attacks. Therefore as an example we use classes O (airplane) and 1 (automobile) from CIFAR10.\n",
        "\n",
        "We choose a sample size for each class (on which we train the target model):"
      ],
      "id": "vaZ15iLZGZ7c"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmHrXo7QGZ7d"
      },
      "source": [
        "NUM_ELEMENTS_PER_CLASSES = {0: 1000, 1: 500}"
      ],
      "id": "WmHrXo7QGZ7d",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrCu1SZzGZ7e"
      },
      "source": [
        "And then adjust the training set accordingly:"
      ],
      "id": "yrCu1SZzGZ7e"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfqQFdCIGZ7e",
        "outputId": "7b637906-a182-476f-ccdc-769dcaeab06d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_set = new_dataset_from_size_dict(train_dataset, NUM_ELEMENTS_PER_CLASSES)\n",
        "print(train_set[0].shape, train_set[1].shape)"
      ],
      "id": "wfqQFdCIGZ7e",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1500, 32, 32, 3) (1500, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2IFaCSoGZ7f"
      },
      "source": [
        "## 2. Load and train your target model\n",
        "\n",
        "Load *your* personal target model in the next cell to perform the attack on it. Any PyTorch or TensorFlow model can be used.\n"
      ],
      "id": "v2IFaCSoGZ7f"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rr4BA37yGZ7i"
      },
      "source": [
        "# For demonstration purposes we load the following ConvNet model for two input classes\n",
        "# (multi-class input will be supported in future releases):\n",
        "\n",
        "num_classes = len(NUM_ELEMENTS_PER_CLASSES)\n",
        "\n",
        "model = ConvNet(num_classes, input_shape, num_channels=(input_shape[-1], 16, 32, 64))  ### <--- Customize this line"
      ],
      "id": "Rr4BA37yGZ7i",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ds3forQVGZ7j"
      },
      "source": [
        "trainer(train_set, NUM_ELEMENTS_PER_CLASSES, model, num_epochs=8)\n",
        "\n",
        "# Convert to ART classifier\n",
        "\n",
        "target_model = Classifier._to_art_classifier(model, num_classes, input_shape)"
      ],
      "id": "Ds3forQVGZ7j",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gG36p_-IGZ7k"
      },
      "source": [
        "## 3. Perform attack\n",
        "\n",
        "Each attack consists of several sub-attack (one for each element in \"ratios_for_attack\").\n",
        "\n",
        "In a sub-attack we create a number of shadow classifiers of the same architecture as the provided target model. \n",
        "\n",
        "Half of them will be trained on an unbalanced data set of the given ratio, the other half is trained on blanced data sets.\n",
        "\n",
        "The shadow classifiers serve as training set for a meta classifier, which finally predicts the likelihood of the target model to have a given property (i.e. the ratio)."
      ],
      "id": "gG36p_-IGZ7k"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNThcpLfGZ7k"
      },
      "source": [
        "# Number of shadow classifiers (increase for better accuracy of the meta classifier, decrease when not enough computing power is available.)\n",
        "amount_sets = 1000 # needs to be even\n",
        "\n",
        "# Size of data set to train the shadow classifiers\n",
        "size_set = 100\n",
        "\n",
        "# Ratios to perform the attack for (the real ratios of our example target model is 0.66, so we )\n",
        "ratios_for_attack = [0.66,0.33]\n",
        "classes = [0,1]\n",
        "\n",
        "attack = PropertyInferenceAttack(target_model, train_set, verbose=1, size_set=size_set, \\\n",
        "    ratios_for_attack=ratios_for_attack, classes=classes,amount_sets=amount_sets)"
      ],
      "id": "qNThcpLfGZ7k",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3aihZM-GZ7l",
        "outputId": "99216e1b-7da5-427b-f20e-1531275ce0e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "output = attack.attack()"
      ],
      "id": "M3aihZM-GZ7l",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initiating Property Inference Attack ... \n",
            "Extracting features from target model ... \n",
            "(155266,)  --- features extracted from the target model.\n",
            "Creating set of 500 balanced shadow classifiers ... \n",
            "Creating shadow training sets\n",
            "Training shadow classifiers\n",
            "Performing PIA for various ratios ... \n",
            "  0%|          | 0/2 [00:00<?, ?it/s]Creating shadow training sets\n",
            "Training shadow classifiers\n",
            "Epoch 1/2\n",
            "8/8 [==============================] - 466s 57s/step - loss: 1.0554 - accuracy: 0.4860\n",
            "Epoch 2/2\n",
            "8/8 [==============================] - 436s 54s/step - loss: 0.9980 - accuracy: 0.5120\n",
            " 50%|█████     | 1/2 [15:37<15:37, 937.82s/it]Creating shadow training sets\n",
            "Training shadow classifiers\n",
            "Epoch 1/2\n",
            "8/8 [==============================] - 454s 55s/step - loss: 1.0918 - accuracy: 0.5070\n",
            "Epoch 2/2\n",
            "8/8 [==============================] - 471s 59s/step - loss: 1.0622 - accuracy: 0.5020\n",
            "100%|██████████| 2/2 [31:15<00:00, 937.70s/it]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vokop1MmGZ7l",
        "outputId": "36a8d0be-4447-40c2-bb1e-6e27b450e84f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "output"
      ],
      "id": "Vokop1MmGZ7l",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('The most probable property is class 0: 0.67, class 1: 0.33 with a probability of 0.4928487241268158.',\n",
              " {'class 0: 0.34, class 1: 0.66': 0.45413798,\n",
              "  'class 0: 0.67, class 1: 0.33': 0.49284872})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Jf9lG3ZGZ7m"
      },
      "source": [
        "## Human readable output of the attack:"
      ],
      "id": "_Jf9lG3ZGZ7m"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2jl8mO7GZ7m",
        "outputId": "5f441506-c0bb-4dab-c497-19431b1104d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "output[0]"
      ],
      "id": "T2jl8mO7GZ7m",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The most probable property is class 0: 0.67, class 1: 0.33 with a probability of 0.4928487241268158.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    }
  ]
}